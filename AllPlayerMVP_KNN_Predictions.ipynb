{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>PlayerID</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Season</th>\n",
       "      <th>Tm</th>\n",
       "      <th>2P</th>\n",
       "      <th>2P%</th>\n",
       "      <th>2PA</th>\n",
       "      <th>3P</th>\n",
       "      <th>3P%</th>\n",
       "      <th>...</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>ORB</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>Rk</th>\n",
       "      <th>STL</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TRB</th>\n",
       "      <th>MVP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11080</th>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>adamsst01</td>\n",
       "      <td>C</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>OKC</td>\n",
       "      <td>261</td>\n",
       "      <td>0.593</td>\n",
       "      <td>440</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>1564</td>\n",
       "      <td>196</td>\n",
       "      <td>111</td>\n",
       "      <td>633</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>86</td>\n",
       "      <td>543</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11081</th>\n",
       "      <td>Bam Adebayo</td>\n",
       "      <td>adebaba01</td>\n",
       "      <td>PF</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>MIA</td>\n",
       "      <td>407</td>\n",
       "      <td>0.576</td>\n",
       "      <td>706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>2235</td>\n",
       "      <td>165</td>\n",
       "      <td>164</td>\n",
       "      <td>1053</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>185</td>\n",
       "      <td>683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11082</th>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>aldrila01</td>\n",
       "      <td>C</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>SAS</td>\n",
       "      <td>330</td>\n",
       "      <td>0.519</td>\n",
       "      <td>636</td>\n",
       "      <td>61</td>\n",
       "      <td>0.389</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>1754</td>\n",
       "      <td>103</td>\n",
       "      <td>128</td>\n",
       "      <td>1001</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>74</td>\n",
       "      <td>392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11083</th>\n",
       "      <td>Nickeil Alexander-Walker</td>\n",
       "      <td>alexani01</td>\n",
       "      <td>SG</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>NOP</td>\n",
       "      <td>37</td>\n",
       "      <td>0.336</td>\n",
       "      <td>110</td>\n",
       "      <td>40</td>\n",
       "      <td>0.342</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>211</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11084</th>\n",
       "      <td>Grayson Allen</td>\n",
       "      <td>allengr01</td>\n",
       "      <td>SG</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>MEM</td>\n",
       "      <td>47</td>\n",
       "      <td>0.534</td>\n",
       "      <td>88</td>\n",
       "      <td>34</td>\n",
       "      <td>0.370</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>5</td>\n",
       "      <td>38</td>\n",
       "      <td>226</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11713</th>\n",
       "      <td>Thaddeus Young</td>\n",
       "      <td>youngth01</td>\n",
       "      <td>PF</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>CHI</td>\n",
       "      <td>190</td>\n",
       "      <td>0.501</td>\n",
       "      <td>379</td>\n",
       "      <td>79</td>\n",
       "      <td>0.356</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>1591</td>\n",
       "      <td>94</td>\n",
       "      <td>134</td>\n",
       "      <td>659</td>\n",
       "      <td>516</td>\n",
       "      <td>92</td>\n",
       "      <td>102</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11714</th>\n",
       "      <td>Trae Young</td>\n",
       "      <td>youngtr01</td>\n",
       "      <td>PG</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>ATL</td>\n",
       "      <td>341</td>\n",
       "      <td>0.501</td>\n",
       "      <td>681</td>\n",
       "      <td>205</td>\n",
       "      <td>0.361</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>2120</td>\n",
       "      <td>32</td>\n",
       "      <td>104</td>\n",
       "      <td>1778</td>\n",
       "      <td>517</td>\n",
       "      <td>65</td>\n",
       "      <td>289</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11715</th>\n",
       "      <td>Cody Zeller</td>\n",
       "      <td>zelleco01</td>\n",
       "      <td>C</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>CHO</td>\n",
       "      <td>233</td>\n",
       "      <td>0.577</td>\n",
       "      <td>404</td>\n",
       "      <td>18</td>\n",
       "      <td>0.240</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>1341</td>\n",
       "      <td>160</td>\n",
       "      <td>140</td>\n",
       "      <td>642</td>\n",
       "      <td>518</td>\n",
       "      <td>40</td>\n",
       "      <td>75</td>\n",
       "      <td>411</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11716</th>\n",
       "      <td>Ante Žižić</td>\n",
       "      <td>zizican01</td>\n",
       "      <td>C</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>CLE</td>\n",
       "      <td>41</td>\n",
       "      <td>0.569</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "      <td>96</td>\n",
       "      <td>519</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11717</th>\n",
       "      <td>Ivica Zubac</td>\n",
       "      <td>zubaciv01</td>\n",
       "      <td>C</td>\n",
       "      <td>2019-20</td>\n",
       "      <td>LAC</td>\n",
       "      <td>203</td>\n",
       "      <td>0.602</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>1172</td>\n",
       "      <td>167</td>\n",
       "      <td>150</td>\n",
       "      <td>513</td>\n",
       "      <td>520</td>\n",
       "      <td>14</td>\n",
       "      <td>55</td>\n",
       "      <td>464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Player   PlayerID Pos   Season   Tm   2P    2P%  2PA  \\\n",
       "11080              Steven Adams  adamsst01   C  2019-20  OKC  261  0.593  440   \n",
       "11081               Bam Adebayo  adebaba01  PF  2019-20  MIA  407  0.576  706   \n",
       "11082         LaMarcus Aldridge  aldrila01   C  2019-20  SAS  330  0.519  636   \n",
       "11083  Nickeil Alexander-Walker  alexani01  SG  2019-20  NOP   37  0.336  110   \n",
       "11084             Grayson Allen  allengr01  SG  2019-20  MEM   47  0.534   88   \n",
       "...                         ...        ...  ..      ...  ...  ...    ...  ...   \n",
       "11713            Thaddeus Young  youngth01  PF  2019-20  CHI  190  0.501  379   \n",
       "11714                Trae Young  youngtr01  PG  2019-20  ATL  341  0.501  681   \n",
       "11715               Cody Zeller  zelleco01   C  2019-20  CHO  233  0.577  404   \n",
       "11716                Ante Žižić  zizican01   C  2019-20  CLE   41  0.569   72   \n",
       "11717               Ivica Zubac  zubaciv01   C  2019-20  LAC  203  0.602  337   \n",
       "\n",
       "        3P    3P%  ...  GS    MP  ORB   PF   PTS   Rk  STL  TOV  TRB  MVP  \n",
       "11080    1  0.333  ...  58  1564  196  111   633    1   50   86  543    0  \n",
       "11081    1  0.077  ...  65  2235  165  164  1053    2   78  185  683    0  \n",
       "11082   61  0.389  ...  53  1754  103  128  1001    3   36   74  392    0  \n",
       "11083   40  0.342  ...   0   501    8   46   211    4   11   40   80    0  \n",
       "11084   34  0.370  ...   0   520    5   38   226    5    8   25   68    0  \n",
       "...    ...    ...  ...  ..   ...  ...  ...   ...  ...  ...  ...  ...  ...  \n",
       "11713   79  0.356  ...  16  1591   94  134   659  516   92  102  315    0  \n",
       "11714  205  0.361  ...  60  2120   32  104  1778  517   65  289  255    0  \n",
       "11715   18  0.240  ...  39  1341  160  140   642  518   40   75  411    0  \n",
       "11716    0  0.000  ...   0   221   18   27    96  519    7   10   66    0  \n",
       "11717    0  0.000  ...  63  1172  167  150   513  520   14   55  464    0  \n",
       "\n",
       "[638 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvp = pd.read_csv(\"Data/AllPlayerData.csv\")\n",
    "mvp = mvp.drop(\"Table Name\", axis = 1)\n",
    "mvp\n",
    "mvp_2020 = mvp.loc[mvp[\"Season\"] == \"2019-20\"]\n",
    "mvp_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = mvp[\"MVP\"]\n",
    "target_names = [\"winner\", \"loser\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2P</th>\n",
       "      <th>2P%</th>\n",
       "      <th>2PA</th>\n",
       "      <th>3P</th>\n",
       "      <th>3P%</th>\n",
       "      <th>3PA</th>\n",
       "      <th>Age</th>\n",
       "      <th>AST</th>\n",
       "      <th>BLK</th>\n",
       "      <th>DRB</th>\n",
       "      <th>...</th>\n",
       "      <th>FTA</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>ORB</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>STL</th>\n",
       "      <th>TOV</th>\n",
       "      <th>TRB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>0.500</td>\n",
       "      <td>232</td>\n",
       "      <td>4</td>\n",
       "      <td>0.286</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>486</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>266</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>0.386</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>0.400</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>420</td>\n",
       "      <td>14</td>\n",
       "      <td>54</td>\n",
       "      <td>111</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>592</td>\n",
       "      <td>0.487</td>\n",
       "      <td>1216</td>\n",
       "      <td>12</td>\n",
       "      <td>0.188</td>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>250</td>\n",
       "      <td>77</td>\n",
       "      <td>560</td>\n",
       "      <td>...</td>\n",
       "      <td>531</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>3241</td>\n",
       "      <td>175</td>\n",
       "      <td>238</td>\n",
       "      <td>1663</td>\n",
       "      <td>90</td>\n",
       "      <td>231</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>0.350</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>222</td>\n",
       "      <td>0.421</td>\n",
       "      <td>527</td>\n",
       "      <td>17</td>\n",
       "      <td>0.370</td>\n",
       "      <td>46</td>\n",
       "      <td>23</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>101</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>65</td>\n",
       "      <td>24</td>\n",
       "      <td>1382</td>\n",
       "      <td>42</td>\n",
       "      <td>139</td>\n",
       "      <td>618</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    2P    2P%   2PA  3P    3P%  3PA  Age  AST  BLK  DRB  ...  FTA   G  GS  \\\n",
       "0  116  0.500   232   4  0.286   14   31   76    1   20  ...   29  41   0   \n",
       "1   39  0.386   101   4  0.400   10   26   22   13   45  ...   36  29  12   \n",
       "2  592  0.487  1216  12  0.188   64   24  250   77  560  ...  531  81  81   \n",
       "3   14  0.350    40   4  0.250   16   27   36    0   25  ...   18  26   0   \n",
       "4  222  0.421   527  17  0.370   46   23   62    5  101  ...  150  65  24   \n",
       "\n",
       "     MP  ORB   PF   PTS  STL  TOV  TRB  \n",
       "0   486    5   50   266    9   26   25  \n",
       "1   420   14   54   111   14   34   59  \n",
       "2  3241  175  238  1663   90  231  735  \n",
       "3   227    0   29    52   16   25   25  \n",
       "4  1382   42  139   618   45   75  143  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mvp.drop([\"Player\", \"PlayerID\", \"Pos\", \"Season\", \"Tm\", \"Rk\", \"MVP\"], axis=1)\n",
    "feature_names = data.columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train.values.reshape(-1,1))\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.996\n",
      "k: 3, Train/Test Score: 0.999/0.997\n",
      "k: 5, Train/Test Score: 0.999/0.997\n",
      "k: 7, Train/Test Score: 0.999/0.998\n",
      "k: 9, Train/Test Score: 0.999/0.998\n",
      "k: 11, Train/Test Score: 0.999/0.998\n",
      "k: 13, Train/Test Score: 0.999/0.998\n",
      "k: 15, Train/Test Score: 0.999/0.998\n",
      "k: 17, Train/Test Score: 0.999/0.998\n",
      "k: 19, Train/Test Score: 0.999/0.998\n"
     ]
    }
   ],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE value for k=  1 is: 0.055422670045287475\n",
      "RMSE value for k=  2 is: 0.053063166685593424\n",
      "RMSE value for k=  3 is: 0.05002843332615361\n",
      "RMSE value for k=  4 is: 0.046645127484966076\n",
      "RMSE value for k=  5 is: 0.04570270453009524\n",
      "RMSE value for k=  6 is: 0.04556558987503444\n",
      "RMSE value for k=  7 is: 0.044788280937699786\n",
      "RMSE value for k=  8 is: 0.043754570702246455\n",
      "RMSE value for k=  9 is: 0.04426394900074082\n",
      "RMSE value for k=  10 is: 0.04324704807539464\n",
      "RMSE value for k=  11 is: 0.0437308935758616\n",
      "RMSE value for k=  12 is: 0.044513124787489436\n",
      "RMSE value for k=  13 is: 0.04480392171376311\n",
      "RMSE value for k=  14 is: 0.0451175397595455\n",
      "RMSE value for k=  15 is: 0.04550312844762486\n",
      "RMSE value for k=  16 is: 0.04561919933671422\n",
      "RMSE value for k=  17 is: 0.04535668898632185\n",
      "RMSE value for k=  18 is: 0.0454846048855108\n",
      "RMSE value for k=  19 is: 0.04526286547292342\n",
      "RMSE value for k=  20 is: 0.04563731483248608\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neighbors\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "rmse_val = [] #to store rmse values for different k\n",
    "for K in range(20):\n",
    "    K = K+1\n",
    "    model = neighbors.KNeighborsRegressor(n_neighbors = K)\n",
    "\n",
    "    model.fit(X_train, y_train)  #fit the model\n",
    "    pred=model.predict(X_test) #make prediction on test set\n",
    "    error = sqrt(mean_squared_error(y_test,pred)) #calculate rmse\n",
    "    rmse_val.append(error) #store rmse values\n",
    "    print('RMSE value for k= ' , K , 'is:', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1698c3fe400>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hU953v8fdXvVCEOkiiC2TApokWOzbg2EbEa1I2Nk5c1smG4Ji03TyJc3M3u9l7c6+vk93NOvHaJolvghu2rxtOMNhxjQtFophqEFUCgSRAAlRQ+90/ZnDEWKABjXRGms/reebRzDm/c+Y7h+F85vxOM+ccIiISeaK8LkBERLyhABARiVAKABGRCKUAEBGJUAoAEZEIpQAQEYlQQQWAmc0zs4/MrNTM7u1gvJnZA/7xH5rZlHbj9pvZFjPbZGbFAdN9yz/fbWZ2f9c/joiIBCumswZmFg08CFwHlAPrzWyFc257u2ZFQL7/MQN4yP/3rDnOueqA+c4BFgBXOOfOmFlmlz6JiIhclGC2AKYDpc65vc65JmA5vhV3ewuAZc5nDZBiZoM7me/dwH3OuTMAzrnKi6xdRES6oNMtACAHKGv3upxzf92fr00OUAE44FUzc8Ajzrml/jZjgE+b2c+ARuD7zrn1FyokPT3dDR8+PIiSRUTkrJKSkmrnXEbg8GACwDoYFnj9iAu1udI5d9jfxfOame10zr3jf+9BwExgGvCMmY10AdemMLNFwCKAoUOHUlx8zm4EERHphJkd6Gh4MF1A5UBeu9e5wOFg2zjnzv6tBF7A16V0dprn/d1G64A2ID3wzZ1zS51zhc65woyMTwSYiIhcomACYD2Qb2YjzCwOWAisCGizArjDfzTQTKDWOVdhZslm1h/AzJKB64Gt/mleBOb6x40B4oBqRESkR3TaBeScazGzJcBqIBp41Dm3zcwW+8c/DKwE5gOlQD1wl3/yLOAFMzv7Xk8651b5xz0KPGpmW4Em4M7A7h8REek+1pvWuYWFhU77AESkpzU3N1NeXk5jY6PXpVxQQkICubm5xMbGnjPczEqcc4WB7YPZCSwiEtHKy8vp378/w4cPx9+jEXaccxw7dozy8nJGjBgR1DS6FISISCcaGxtJS0sL25U/gJmRlpZ2UVspCgARkSCE88r/rIutMSIC4N3d1fzXW6VelyEiElYiIgD+sruKf3t1FxW1DV6XIiJyyVatWsXYsWMZPXo09913X5fnFxEBcNvMYbQ5x1NrD3pdiojIJWltbeWee+7hlVdeYfv27Tz11FNs37698wkvICICIC81iTljM3lyXRlNLW1elyMictHWrVvH6NGjGTlyJHFxcSxcuJCXXnqpS/OMmMNAb581jLv+73pWbTvCTROHeF2OiPRSP315G9sPnwzpPMcNGcA//834C7Y5dOgQeXl/veJObm4ua9eu7dL7RsQWAMA1+RkMS0visQ/2e12KiMhF6+ik3a4emRQxWwBRUcZtM4bxs5U72FFxkssGD/C6JBHphTr7pd5dcnNzKSv761X3y8vLGTKka70ZEbMFAPClwlziY6JY9kGHV0YVEQlb06ZNY/fu3ezbt4+mpiaWL1/OTTfd1KV5RlQApCTFsWDSEF7ceIjahmavyxERCVpMTAy//vWvueGGG7jsssu4+eabGT++a1sjEdMFdNYds4bzTHE5z5WU89WrgrtehohIOJg/fz7z588P2fwiagsAYELOQCYPTeHxNQdoa+s9V0IVEQm1iAsAgDtmDWNvdR3v7dH9Z0QkckVkAMy/fDBpyXHaGSwiQesN90652BojMgDiY6K5ZVoer+84yqEaXR9IRC4sISGBY8eOhXUInL0fQEJCQtDTRNxO4LO+MnMYD7+9hyfWHOAH8wq8LkdEwlhubi7l5eVUVVV5XcoFnb0jWLAiNgByUhK59rIsnl5fxnc+k098TLTXJYlImIqNjQ36Llu9SUR2AZ11x6xhHKtrYuWWCq9LERHpcREdAFeOSmdkerJ2BotIRIroAIiKMm6fNYyNB2vYeqjW63JERHpURAcAwBen5pIUF82yD/Z7XYqISI+K+AAYkBDL5ybn8NKmw5yoa/K6HBGRHhNUAJjZPDP7yMxKzezeDsabmT3gH/+hmU1pN26/mW0xs01mVtzBtN83M2dm6V37KJfujlnDONPSxrMlZZ03FhHpIzoNADOLBh4EioBxwK1mNi6gWRGQ738sAh4KGD/HOTfJOVcYMO884DrA05v1FmQPYPrwVB5fc1DXBxKRiBHMFsB0oNQ5t9c51wQsBxYEtFkALHM+a4AUMxscxLz/A/gB4Pla9/ZZwzh4vJ63d4X3iR4iIqESTADkAO37Rsr9w4Jt44BXzazEzBadbWBmNwGHnHObL/TmZrbIzIrNrLg7z8K7YXw2Gf3jtTNYRCJGMAHQ0U0nA3+xX6jNlc65Kfi6ie4xs6vNLAn4MfCTzt7cObfUOVfonCvMyMgIotxLExcTxa3Th/LWrioOHqvvtvcREQkXwQRAOZDX7nUucDjYNs65s38rgRfwdSmNAkYAm81sv7/9BjPLvviPEDpfnj6UKDMeX6sTw0Sk7wsmANYD+WY2wszigIXAioA2K4A7/EcDzQRqnXMVZpZsZv0BzCwZuB7Y6pzb4pzLdM4Nd84NxxcgU5xzR0L1wS5F9sAEbhifxTPFZTQ2t3pZiohIt+s0AJxzLcASYDWwA3jGObfNzBab2WJ/s5XAXqAU+A3wTf/wLOBdM9sMrAP+5JxbFeLPEFK3zxxOTX0zKzYHbuSIiPQtFs7Xtw5UWFjoios/cSpBSDnnuOGX7xAfE82KJVdi1tHuDRGR3sPMSgIPwwedCfwJZsbtM4ex5VAtm8pqvC5HRKTbKAA68PkpufSLj+ExXSVURPowBUAH+sXH8IUpOfzxwwqOnT7jdTkiIt1CAXAet88cRlNrG08X6/pAItI3KQDOIz+rP7NGpvHEmoO06vpAItIHKQAu4I5ZwzhU08AbOyu9LkVEJOQUABdw3bgssgck6PpAItInKQAuICY6ii/PGMpfdlezt+q01+WIiISUAqATC6fnERttPLZGh4SKSN+iAOhEZv8EiiYM5rmScppa2rwuR0QkZBQAQVgwaQgnG1t4b0+116WIiISMAiAIV+Wn0y8+hlVbPL1YqYhISCkAghAfE821l2Xy6vYjtLSqG0hE+gYFQJCKJmRzor6ZdfuOe12KiEhIKACCdM2YTBJjo1m5tcLrUkREQkIBEKTEuGhmj81g9bajtOnSECLSBygALkLR5YOpOnWGkoMnvC5FRKTLFAAXYW5BJnExUbyio4FEpA9QAFyEfvExXJ2fzqqtFfSmW2mKiHREAXCR5k0YzOHaRjaX13pdiohIlygALtJ1l2URE2W8oqOBRKSXUwBcpIFJsXxqdDqrth5RN5CI9GoKgEtQNCGbA8fq2VFxyutSREQuWVABYGbzzOwjMys1s3s7GG9m9oB//IdmNqXduP1mtsXMNplZcbvhPzeznf72L5hZSmg+Uve7flwWUYa6gUSkV+s0AMwsGngQKALGAbea2biAZkVAvv+xCHgoYPwc59wk51xhu2GvAROcc1cAu4AfXdpH6Hlp/eKZMSKNV7bqcFAR6b2C2QKYDpQ65/Y655qA5cCCgDYLgGXOZw2QYmaDLzRT59yrzrkW/8s1QO5F1u6posuzKa08TWmluoFEpHcKJgBygLJ2r8v9w4Jt44BXzazEzBad5z2+CrwSRC1h44bx2QA6KUxEeq1gAsA6GBZ4+MuF2lzpnJuCr5voHjO7+pwJzX4MtABPdPjmZovMrNjMiquqqoIot2dkDUhg6rBBrFQ3kIj0UsEEQDmQ1+51LnA42DbOubN/K4EX8HUpAWBmdwI3Al9x5zmm0jm31DlX6JwrzMjICKLcnlM0IZsdFSc5cKzO61JERC5aMAGwHsg3sxFmFgcsBFYEtFkB3OE/GmgmUOucqzCzZDPrD2BmycD1wFb/63nAD4GbnHP1Ifo8PWreBH83kLYCRKQX6jQA/DtqlwCrgR3AM865bWa22MwW+5utBPYCpcBvgG/6h2cB75rZZmAd8Cfn3Cr/uF8D/YHX/IeIPhyqD9VTcgclcUXuQAWAiPRKMcE0cs6txLeSbz/s4XbPHXBPB9PtBSaeZ56jL6rSMDVvQjb3r/qIQzUN5KQkel2OiEjQdCZwFxVN8B3tukpbASLSyygAumhEejIF2f1ZpbOCRaSXUQCEQNGEwRQfOEHlqUavSxERCZoCIASKLs/GOVi97ajXpYiIBE0BEAL5mf0YmZHMK1vUDSQivYcCIATMjKIJ2azdd5zjdU1elyMiEhQFQIgUTRhMa5vjte06GkhEegcFQIiMHzKAvNREnRQmIr2GAiBEfN1Ag3mvtJrahmavyxER6ZQCIITmTcimudXx+g4dDSQi4U8BEEKTclMYPDBB3UAi0isoAEIoKsq4YXw2b++q4vSZls4nEBHxkAIgxIomZNPU0sabOyu9LkVE5IIUACFWODyV9H5xujiciIQ9BUCIRfu7gd78qJLG5lavyxEROS8FQDcomjCY+qZW3t4VPvcwFhEJpADoBjNGppKSFKtuIBEJawqAbhAbHcV1l2Xx5+1HOdOibiARCU8KgG5SdHk2p8608H7pMa9LERHpkAKgm1w5Op3+8TG8ojuFiUiYUgB0k/iYaK69LJNXtx+lubXN63JERD5BAdCN5k0YTE19M2v3Hve6FBGRT1AAdKNrxmSQGButbiARCUsKgG6UGBfN3IJMVm87Smub87ocEZFzBBUAZjbPzD4ys1Izu7eD8WZmD/jHf2hmU9qN229mW8xsk5kVtxueamavmdlu/99BoflI4WXehGyqT5+h5MAJr0sRETlHpwFgZtHAg0ARMA641czGBTQrAvL9j0XAQwHj5zjnJjnnCtsNuxd43TmXD7zuf93nzCnIJC4mipW6YbyIhJlgtgCmA6XOub3OuSZgObAgoM0CYJnzWQOkmNngTua7APiD//kfgM9dRN29Rr/4GK7Oz2D1tiM4p24gEQkfwQRADlDW7nW5f1iwbRzwqpmVmNmidm2ynHMVAP6/mR29uZktMrNiMyuuquqd19a5fnwWFbWN7Kg45XUpIiIfCyYArINhgT9lL9TmSufcFHzdRPeY2dUXUR/OuaXOuULnXGFGRsbFTBo2Zo/11f3mR7pHgIiEj2ACoBzIa/c6FzgcbBvn3Nm/lcAL+LqUAI6e7Sby/+2za8fM/glcnjOQN3STGBEJI8EEwHog38xGmFkcsBBYEdBmBXCH/2igmUCtc67CzJLNrD+AmSUD1wNb201zp//5ncBLXfwsYW1OQSYbD57gRF2T16WIiABBBIBzrgVYAqwGdgDPOOe2mdliM1vsb7YS2AuUAr8BvukfngW8a2abgXXAn5xzq/zj7gOuM7PdwHX+133WnLEZtDl4Z3fv3I8hIn1PTDCNnHMr8a3k2w97uN1zB9zTwXR7gYnnmecx4NqLKbY3m5ibQlpyHG/srGTBpMB96CIiPU9nAveQqCjjmrEZvL2rSmcFi0hYUAD0oDljM6mpb2ZTmc4KFhHvKQB60NX5GURHmY4GEpGwoADoQQOTYpk6dBBv7tSOYBHxngKgh80pyGR7xUmO1DZ6XYqIRDgFQA+bW+C74oXOChYRrykAetiYrH4MGZjAm9oPICIeUwD0MDNjTkEm75ZWc6al1etyRCSCKQA8MLcgk/qmVtbt072CRcQ7CgAPzBqVRlxMlI4GEhFPKQA8kBQXw6yRadoRLCKeUgB4ZG5BJvuq69hXXed1KSISoRQAHpkz1n84qI4GEhGPKAA8MjQtiVEZyeoGEhHPKAA8NLcgk7V7j1N3psXrUkQkAikAPDRnbCZNrW28V1rtdSkiEoEUAB4qHJ5Kv/gYdQOJiCcUAB6Ki4ni0/npvLmzCt9N1UREeo4CwGNzxmZy5GQjOypOeV2KiEQYBYDHZhdkALo6qIj0PAWAxzL7J3B5zkDdJUxEepwCIAzMGZvBxoMnOFHX5HUpIhJBFABhYE5BJm0O3tmti8OJSM8JKgDMbJ6ZfWRmpWZ2bwfjzcwe8I//0MymBIyPNrONZvbHdsMmmdkaM9tkZsVmNr3rH6d3mpibQlpynLqBRKRHdRoAZhYNPAgUAeOAW81sXECzIiDf/1gEPBQw/jvAjoBh9wM/dc5NAn7ifx2RoqKMa8Zk8PauKlrbdDioiPSMYLYApgOlzrm9zrkmYDmwIKDNAmCZ81kDpJjZYAAzywU+C/w2YBoHDPA/HwgcvsTP0CfMKcikpr6ZTWUnvC5FRCJEMAGQA5S1e13uHxZsm18CPwDaAqb5LvBzMysDfgH8KMia+6Sr8zOIjjJ1A4lIjwkmAKyDYYH9FB22MbMbgUrnXEkH4+8GvuecywO+B/yuwzc3W+TfR1BcVdV3d5IOTIpl6tBBukuYiPSYYAKgHMhr9zqXT3bXnK/NlcBNZrYfX9fRXDN73N/mTuB5//Nn8XU1fYJzbqlzrtA5V5iRkRFEub3XnIJMtlec5Ehto9eliEgECCYA1gP5ZjbCzOKAhcCKgDYrgDv8RwPNBGqdcxXOuR8553Kdc8P9073hnLvNP81h4Br/87nA7q5+mN5uboH/JjE6K1hEekBMZw2ccy1mtgRYDUQDjzrntpnZYv/4h4GVwHygFKgH7grivb8O/KeZxQCN+I4eimhjsvoxZGACb+6s5NbpQ70uR0T6uE4DAMA5txLfSr79sIfbPXfAPZ3M4y3grXav3wWmBl9q32dmzCnI5IWNhzjT0kp8TLTXJYlIH6YzgcPM3IJM6ptaWbfvuNeliEgfpwAIM7NGpREXE6WjgUSk2ykAwkxSXAyzRqZpR7CIdDsFQBiaW5DJvuo69lXXeV2KiPRhCoAwNGes/3BQnRUsIt1IARCGhqYlMSojWd1AItKtFABhas7YTNbuPU7dmRavSxGRPkoBEKbmFmTS1NrGe6XVXpciIn2UAiBMFQ5PpV98jLqBRKTbKADCVFxMFFeNTufNnVX4TrQWEQktBUAYm1uQyZGTjeyoOOV1KSLSBykAwtjssb7LX6sbSES6gwIgjGUOSGBCzgDdJUxEuoUCIMzNHZvJxoMnOFHX5HUpItLHKADC3JyCTNocvLNbF4cTkdBSAIS5K3JTSE2OUzeQiIScAiDMRUcZs8dk8MaOSkordTSQiISOAqAXuGfuaOJjo7nlkTVsO1zrdTki0kcoAHqBURn9eHbxLOJjorh16Ro2HjzhdUki0gcoAHqJEenJPLN4FoOS47jtt2tZs/eY1yWJSC+nAOhFcgcl8cw3ZjE4JZE7H13HWzpBTES6QAHQy2QNSODpRTMZldGPry8rZtXWI16XJCK9lAKgF0rrF89Ti2YyIWcg9zy5gZc2HfK6JBHphRQAvdTAxFge+9oMpg0fxHef3sTydQe9LklEepmgAsDM5pnZR2ZWamb3djDezOwB//gPzWxKwPhoM9toZn8MGP4t/3y3mdn9XfsokadffAy/v2s614zJ4N7nt/Dou/u8LklEepFOA8DMooEHgSJgHHCrmY0LaFYE5Psfi4CHAsZ/B9gRMN85wALgCufceOAXl/IBIl1CbDSP3D6VeeOz+dc/bufBN0u9LklEeolgtgCmA6XOub3OuSZgOb4Vd3sLgGXOZw2QYmaDAcwsF/gs8NuAae4G7nPOnQFwzumQlksUHxPNr788mc9PzuHnqz/i/lU7dRMZEelUMAGQA5S1e13uHxZsm18CPwDaAqYZA3zazNaa2dtmNq2jNzezRWZWbGbFVVW6INr5xERH8W9fmsit04fyX2/t4acvb1cIiMgFxQTRxjoYFrhm6bCNmd0IVDrnSsxsdgfvPQiYCUwDnjGzkS5greWcWwosBSgsLNQa7QKiooz/9fkJJMZG8+h7+2hsbuVnn7+c6KiO/nlEJNIFEwDlQF6717nA4SDb/C1wk5nNBxKAAWb2uHPuNv80z/tX+OvMrA1IB/QzvwvMjH+68TKS46P51RulNDS38osvTSQ2Wgd8ici5glkrrAfyzWyEmcUBC4EVAW1WAHf4jwaaCdQ65yqccz9yzuU654b7p3vDv/IHeBGYC2BmY4A4oLrrH0nMjH+8fiw/mDeWlzYd5p4nNnCmpdXrskQkzHS6BeCcazGzJcBqIBp41Dm3zcwW+8c/DKwE5gOlQD1wVxDv/SjwqJltBZqAOwO7f6Rrvjl7NEmx0fzLy9u5+eEPmDkqjWGpyQxPS2JoWhKDByaqe0gkgllvWucWFha64uJir8vodZ7fUM6Db5ZSdryBpta/7ouPi44iLzWRYWnJDEtLYlhqEsPSkxmWmkTuoCTiYtRtJN5pbm3j6MlGDtc0UlPfxMS8FLIGJHhdVo9qbm3jrY+q+H8lZfzz34xnSEriJc3HzEqcc4WBw4PZByC93Bem5PKFKbm0tjkqahs4eKye/cfqOXC8jgPV9Rw4Xs+avceob/prN1GUwZCURIanJTM0LYlJuSn87dRcorTFICHgnONkQwuHaho4XNPA4doG//NG3+uaBo6ebKQt4PfpmKx+XDk6natGpzNjZBr94vvmKmz30VM8W1LO8xsOUX36DOn94thbVXfJAXA+2gIQwPcfsvp0EweO1XHgWL3v73F/UByro6a+mWsLMvn3WyYxMDHW63KlFymtPM2r249QfqLh45X7oRMN1DWdu18qLjqKwSkJ5KQkMsT/yElJYEhKIklxMZQcOM5fdlezbt9xzrS0ERNlTMpL8QVCfjqT8lK65WCH+qYWjp1uYkhK93aZ1jY08/LmwzxbUs7mshpiooy5BZl8qTCP2WMzuvTZzrcFoACQTjnneHzNAX768nZyBiXyyO1TKcge4HVZEsbqm1pYueUIT68/yPr9vhsYpSbHMSQlgSEDE8kZlHjOin5ISgLpyfFBbWE2Nrey4eAJ3iut5t3SY2wpr6HNQXJcNDNGpnHl6HQ+nZ9OfmY/zDqfX3NrG4drGig73kDZiXrKjtdz8Hg9ZScaKD9ez7G6JsB36ZVJeSlMGTaIKUNTmDx0UJd/DLW1Od7bU82zxeWs3naEMy1tFGT352+n5vK5yTmk94vv0vzPUgBIl5UcOM7dj2/gVGML933xchZMCjwfUCKZc46th06yfP1BVmw6zKkzLYxIT+aWaXl8YUoOmf27p/++tr6ZD/ZW825pNe+VHmNfdR0AGf3juWp0OleOTmfy0BRq6pt8K/bjDZQdr/ev7BuoqG04p6spJsoYkpJIXmoieYOSyEtNYlBSHNsratlwoIadR05+3D4/sx9Thw1iytBBTBk2iJHpyUGF2IFjdfy/knKeKynncG0jAxJiWDAphy8V5nJ5zsCggutiKAAkJCpPNXLPExtYv/8EX7tqBPcWFegcgwhXW9/MS5sPsXxdGdsrThIfE8VnLx/MLdPymD4iNeQrs86Un6jn/dJj/kCo/vgXfHsZ/eMZmppE3qBE8lKTyBuURG5qIkNTk8gekEDMBb7Tp8+08GFZDSUHTrDh4Ak2HKyhtqEZ8F2ld/LQFKb6A2FiXsrH+ynObhU9W1zG2n3HMYNP52fwpam5XDcui4TY6O5ZICgAJISaW9v42Z928Pv39zN9RCoPfnkKGf1Ds6kqvYNzjrX7jvP0+jJWbqngTEsb4wYP4Nbpedw0KSds9hO1tTk+OnqKLYdqyegXT15qIrmDkkK6sm1rc+ytrmODPxBKDpxgd+VpwHcwxdjsAQxLTeIvu6uoa2pleFoSXyr0bRUNHhjanbrnowCQkHtx4yHuff5DBibG8tBtU5kydJDXJUk3qzzVyHMlh3imuIx91XX0j49hweQhLJw2lAk5A70uL2zU1jezseyEPxRq2FN1mqtGp/OlwjymDR/U41tFCgDpFtsPn2Tx4yVU1Dbwz38znq/MGNrjX27pXs2tbfxldxXL15Xx+s5KWtsc04encsu0POZfPpjEuO7rupDQ0HkA0i3GDRnAy0uu4jtPb+S/v7iVzWU1/I/PTejW/kzpfg1Nrby9q4pXtx3hzzuOcrKxhbTkOP7+qhHcPC2PURn9vC5RQkABIF02MCmWR++cxi9f380Dr+9mx5GTPHzbVHIHJXldmlyE2vpmXt95lNXbjvD2rioam9sYmBjLZ8ZlMW98NrPHZurs8D5GXUASUn/efpTvPbOJmCjjgVsn8+n8DK9LkguoPNnI6u1HeXXbET7Yc4yWNkfWgHiuH5fNvAnZTB+RqqO8+gDtA5Aes6+6jsWPlbC78hTfv2Esd18zSvsFwsj+6jpWbzvC6m1H2FhWg3MwPC2JGyZkM298NhNzU3TJjz5G+wCkx4xIT+aFez7FD5/bwv2rPuLDslp+cfPEPnvdlnDnnGNHxamPV/o7j5wCYPyQAXzvM2O4YXw2Y7KCO2tW+hZtAUi3cc7xu3f38b9f2cnI9GSe+PqMbjsbVM7V2NzK+3uqeWNnJW/urOJQTQNmMG1YKtePz+KG8dnkpWofTaRQF5B45v091fz9H4rJG5TE8kUzGZQc53VJfdLhmgbe2FnJGzsreX9PNY3NbSTFRXPl6HTmFmTymcuydMJehFIAiKfeL63m736/nrFZ/Xni6zMYkBAeZ4r2Zq1tjo0HT3y80j/btZOXmsi1BVnMKchkxohUHZIrCgDx3hs7j/KNx0qYmJvCsq9NJylO+wQuVm19M2/vruKNHUd5e1cVJ+qbiY4yCocN4trLMplbkMmoDPXny7m0E1g8N7cgi/9cOJklT25g0bISfntnoX6dBuFUYzNPrj3I6zsrKTlwgtY2x6CkWOaMzWROQSZXj8kIm2vvSO+iAJAeNf/ywfz8byfyj89u5p4nNvDw7VN1nPkF7D56im88VsLe6jouGzyAu68ZxZyCTCblpeh+ztJlCgDpcV+cmkt9cyv/9OJWvvv0Jh5YOFkrsw68sqWC7z+7mcS4aJ5eNJMZI9O8Lkn6GAWAeOL2mcNobGrlZyt3kBgbzf1fvEInH/m1tjl+8epHPPTWHiblpfDwbVPJHqjDZyX0FADima9fPZK6phZ++efdJMVF89ObxnfLzssTdU2UVhq9URIAAAtbSURBVJ1m2vDUkM871E7UNfHt5Rv5y+5qbp0+lH+5aRzxMdpPIt1DASCe+s61+dQ3tbL0nb0kxkVz77yCkIXAycZmfveXffzu3X2cPtPCvUUFLL5mVEjm3R22Ha7lG4+VUHnyDPd94XIWTh/qdUnSxwUVAGY2D/hPIBr4rXPuvoDx5h8/H6gH/s45t6Hd+GigGDjknLsxYNrvAz8HMpxz1V34LNILmRk/KiqgvqmFR97eS3JcDN++Nr9L86xvauEP7x/gkXf2UFPfTNGEbJyD+17ZSXxMFHddOSJE1YfO2ZvrpCTG8fQ3ZjJZN9eRHtBpAPhX3g8C1wHlwHozW+Gc296uWRGQ73/MAB7y/z3rO8AOYEDAvPP88z3Yhc8gvZyZ8a83TaC+qZV/f20XSXHR/P2nR170fBqbW3ly7UH+661Sqk83Mbcgk3+4bgwTcgbS3NrGkic38NOXtxMXE8VXZgzrhk9y8Zpb2/hfK3fwf9/T7TWl5wWzBTAdKHXO7QUws+XAAqB9ACwAljnfWWVrzCzFzAY75yrMLBf4LPAz4B8C5v0fwA+Al7r4OaSXi4oy7v/iFTQ2t/I//7SDpLgYvjwjuC6QppY2ni0p41evl3LkZCOfGpXGI7ePYeqwv/b5x0ZH8atbp7D48RJ+/MJWYqOjuLkwr7s+TlCqTp1hyZMbWLvvOHddOZz/Nv8yHRIrPSqYAMgBytq9LufcX/fna5MDVAC/xLeS799+AjO7CV+X0GadtSgAMdFR/PKWyTQ2l/DjF7eQGBfF5yfnnrd9a5vjxY2H+OXruyg73sCUoSn8+80T+dTo9A7bx8VE8V9fmcLXlxXzw+c+JD4migWTcrrr41zQprIaFj9WQk1DE/9xy8QLfk6R7hJMAHS0dg68fkSHbczsRqDSOVdiZrM/bmyWBPwYuL7TNzdbBCwCGDpUO8X6urMr6a/+fj3/+MxmEmKiKbp88Dlt2tocK7dW8B+v7WJPVR0Tcgbwr3dNYPaYjE53ICfERrP09kLu+v06/uGZzcRFR31i/t1t+bqD/OSlbWQOiOe5uz/F+CG6mbp4I5jtzXKg/bZyLnA4yDZXAjeZ2X5gOTDXzB4HRgEjgM3+cbnABjPLDnxz59xS51yhc64wI0N3l4oECbHR/OaOQiblpfDt5Rt586NKwHd56de2H2X+A39hyZMbiY4yHr5tCi8vuYo5YzODPnooMS6a3905jUl5KXzrqY38efvR7vw4HzvT0sqPnt/Cvc9vYcbIVF5ecpVW/uKpTi8GZ2YxwC7gWuAQsB74snNuW7s2nwWW4DsKaAbwgHNuesB8ZgPfDzwKyD9uP1DY2VFAuhhcZKltaObLv1lDaeVpfjivgJc2H2ZzWQ3D05L43nVjuPGKIV06g/hkYzO3/3YtOypOsfSOqcwemxnC6s91pLaRu58oYePBGu6ePYrvXz9WZz9LjznfxeA63QJwzrXgW7mvxnckzzPOuW1mttjMFvubrQT2AqXAb4BvhqxyiVgDE2N57GszGJqaxL/+cTvVp85w/xev4M//cA0LJuV0eQU6ICGWZV+dwejMfnzjsRLeLw39UcgtrW28uPEQN/7qXXYdOcVDX5nCD+cVaOUvYUGXg5awd+z0GT7Ye4zrxmV1y1mxx+uaWLj0A8qON7Dsa9NDcsZws3/F/+Cbpew/Vk9Bdn9+detk8rP6dz6xSIjpfgAiF1B16gy3LP2AypNneOxr0y/5RKymljae21DOg2+WUn6igXGDB/Dta/O5flyWrnUknlEAiHTiSG0jtyz9gON1TTz19ZlMyAl+B21jcyvPFpfx0Ft7OFzbyMTcgXz72nzmFgS/c1qkuygARIJwqKaBmx/+gLqmFpYvmklB9oALtm9oauWpdQd55J09HD15hqnDBvHta/O5Oj9dK34JGwoAkSAdPFbPzY98QHNrG09/YyajMz/Zb193poUn1h5g6Tt7qT7dxIwRqXzn2nxmjUrTil/CjgJA5CLsrTrNzY+sIcrg6W/MYkR6MuC7PeOyDw7wu3f3cbyuiatGp/OtuaN1sxYJawoAkYu06+gpFi5dQ3xMFL+9s5DXd1Tyu3f3UdvQzOyxGXxrbj5Th+mqnRL+FAAil2D74ZPc+ps11DY0A/CZy7L49rWjuSI3xePKRIJ3vgDQDWFELmDckAE88fczeHp9GQun5+nSDdKnKABEOjEhZ+BFHRIq0lvo4uMiIhFKASAiEqEUACIiEUoBICISoRQAIiIRSgEgIhKhFAAiIhFKASAiEqF61aUgzKwKOHCJk6cDob/nX+iovq5RfV2j+rounGsc5pzLCBzYqwKgK8ysuKNrYYQL1dc1qq9rVF/X9YYaA6kLSEQkQikAREQiVCQFwFKvC+iE6usa1dc1qq/rekON54iYfQAiInKuSNoCEBGRdvpcAJjZPDP7yMxKzezeDsabmT3gH/+hmU3pwdryzOxNM9thZtvM7DsdtJltZrVmtsn/+ElP1ed///1mtsX/3p+4/ZrHy29su+WyycxOmtl3A9r06PIzs0fNrNLMtrYblmpmr5nZbv/fDu8b2dl3tRvr+7mZ7fT/+71gZh3e3qyz70I31vcvZnao3b/h/PNM69Xye7pdbfvNbNN5pu325ddlzrk+8wCigT3ASCAO2AyMC2gzH3gFMGAmsLYH6xsMTPE/7w/s6qC+2cAfPVyG+4H0C4z3bPl18G99BN/xzZ4tP+BqYAqwtd2w+4F7/c/vBf7Peeq/4He1G+u7HojxP/8/HdUXzHehG+v7F+D7Qfz7e7L8Asb/G/ATr5ZfVx99bQtgOlDqnNvrnGsClgMLAtosAJY5nzVAipkN7oninHMVzrkN/uengB1ATk+8dwh5tvwCXAvscc5d6omBIeGcewc4HjB4AfAH//M/AJ/rYNJgvqvdUp9z7lXnXIv/5RogN9TvG6zzLL9geLb8zjIzA24Gngr1+/aUvhYAOUBZu9flfHIFG0ybbmdmw4HJwNoORs8ys81m9oqZje/RwsABr5pZiZkt6mB8WCw/YCHn/4/n5fIDyHLOVYAv9IHMDtqEy3L8Kr4tuo509l3oTkv8XVSPnqcLLRyW36eBo8653ecZ7+XyC0pfCwDrYFjgYU7BtOlWZtYPeA74rnPuZMDoDfi6NSYCvwJe7MnagCudc1OAIuAeM7s6YHw4LL844Cbg2Q5Ge738ghUOy/HHQAvwxHmadPZd6C4PAaOASUAFvm6WQJ4vP+BWLvzr36vlF7S+FgDlQF6717nA4Uto023MLBbfyv8J59zzgeOdcyedc6f9z1cCsWaW3lP1OecO+/9WAi/g29Ruz9Pl51cEbHDOHQ0c4fXy8zt6tlvM/7eygzZefw/vBG4EvuL8HdaBgvgudAvn3FHnXKtzrg34zXne1+vlFwN8AXj6fG28Wn4Xo68FwHog38xG+H8lLgRWBLRZAdzhP5plJlB7dnO9u/n7DH8H7HDO/ft52mT722Fm0/H9Gx3rofqSzaz/2ef4dhZuDWjm2fJr57y/vLxcfu2sAO70P78TeKmDNsF8V7uFmc0Dfgjc5JyrP0+bYL4L3VVf+31Knz/P+3q2/Pw+A+x0zpV3NNLL5XdRvN4LHeoHvqNUduE7QuDH/mGLgcX+5wY86B+/BSjswdquwreZ+iGwyf+YH1DfEmAbvqMa1gCf6sH6Rvrfd7O/hrBafv73T8K3Qh/Ybphnyw9fEFUAzfh+lX4NSANeB3b7/6b62w4BVl7ou9pD9ZXi6z8/+x18OLC+830Xeqi+x/zfrQ/xrdQHh9Py8w///dnvXLu2Pb78uvrQmcAiIhGqr3UBiYhIkBQAIiIRSgEgIhKhFAAiIhFKASAiEqEUACIiEUoBICISoRQAIiIR6v8D5eSfsIISZW4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "curve = pd.DataFrame(rmse_val) \n",
    "curve.plot()\n",
    "\n",
    "## 9 appears to be the best value for k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=9 Test Acc: 0.9976\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print('k=9 Test Acc: %.4f' % knn.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 9}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import neighbors\n",
    "params = {'n_neighbors':[2,3,4,5,6,7,8,9,10]}\n",
    "\n",
    "knn = neighbors.KNeighborsRegressor()\n",
    "\n",
    "model = GridSearchCV(knn, params, cv=5)\n",
    "model.fit(X_train,y_train)\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mvp.drop([\"Player\", \"PlayerID\", \"Pos\", \"Season\", \"Tm\", \"Rk\", \"MVP\"], axis=1)\n",
    "Xx = mvp_2020.drop([\"Player\", \"PlayerID\", \"Pos\", \"Season\", \"Tm\", \"Rk\", \"MVP\"], axis=1)\n",
    "y = mvp[\"MVP\"]\n",
    "y = y.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler1 = StandardScaler().fit(X_train1)\n",
    "y_scaler1 = StandardScaler().fit(y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled1 = X_scaler1.transform(X_train1)\n",
    "X_test_scaled1 = X_scaler1.transform(X_test1)\n",
    "Xx_test_scaled = X_scaler.transform(Xx)\n",
    "y_train_scaled1 = y_scaler1.transform(y_train1)\n",
    "y_test_scaled1 = y_scaler1.transform(y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricks\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.9976109215017065\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_scaler_rf = MinMaxScaler().fit(X_train1)\n",
    "X_train_scaled_rf = X_scaler.transform(X_train1)\n",
    "X_test_scaled_rf = X_scaler.transform(X_test1)\n",
    "Xx_test_scaled_rf = X_scaler.transform(Xx)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train1)\n",
    "encoded_y_train = label_encoder.transform(y_train1)\n",
    "encoded_y_test = label_encoder.transform(y_test1)\n",
    "\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train_scaled_rf, encoded_y_train)\n",
    "\n",
    "print(f\"Training Data Score: {rf.score(X_train_scaled_rf, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {rf.score(X_test_scaled_rf, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] n_estimators=400 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=400, score=0.999, total=   6.6s\n",
      "[CV] n_estimators=400 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=400, score=0.998, total=   5.9s\n",
      "[CV] n_estimators=400 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   12.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_estimators=400, score=0.998, total=   3.5s\n",
      "[CV] n_estimators=400 ................................................\n",
      "[CV] .................... n_estimators=400, score=0.999, total=   5.2s\n",
      "[CV] n_estimators=400 ................................................\n",
      "[CV] .................... n_estimators=400, score=0.999, total=   6.7s\n",
      "[CV] n_estimators=700 ................................................\n",
      "[CV] .................... n_estimators=700, score=0.999, total=  10.5s\n",
      "[CV] n_estimators=700 ................................................\n",
      "[CV] .................... n_estimators=700, score=0.998, total=   9.4s\n",
      "[CV] n_estimators=700 ................................................\n",
      "[CV] .................... n_estimators=700, score=0.998, total=  10.2s\n",
      "[CV] n_estimators=700 ................................................\n",
      "[CV] .................... n_estimators=700, score=0.999, total=  10.8s\n",
      "[CV] n_estimators=700 ................................................\n",
      "[CV] .................... n_estimators=700, score=0.999, total=  11.6s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ................... n_estimators=1000, score=0.999, total=  16.6s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ................... n_estimators=1000, score=0.998, total=  15.0s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ................... n_estimators=1000, score=0.998, total=  13.2s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ................... n_estimators=1000, score=0.999, total=  15.1s\n",
      "[CV] n_estimators=1000 ...............................................\n",
      "[CV] ................... n_estimators=1000, score=0.999, total=  16.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400}\n",
      "0.9986345532869334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = { \n",
    "    'n_estimators': [400, 700, 1000]\n",
    "}\n",
    "grid2 = GridSearchCV(estimator=rf, param_grid=param_grid, verbose=3)\n",
    "\n",
    "grid2.fit(X_train_scaled_rf, encoded_y_train)\n",
    "\n",
    "print(grid2.best_params_)\n",
    "print(grid2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC Prediction\n",
    "predictions = grid2.predict(Xx_test_scaled_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Candidates\n"
     ]
    }
   ],
   "source": [
    "found = 0\n",
    "for i in range(len(predictions)):\n",
    "    if predictions[i] == 1:\n",
    "        found = 1\n",
    "        print(i,mvp_2020.iloc[i,0])\n",
    "if found == 0:\n",
    "    print(\"No Candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.996\n",
      "k: 3, Train/Test Score: 0.999/0.997\n",
      "k: 5, Train/Test Score: 0.999/0.997\n",
      "k: 7, Train/Test Score: 0.999/0.998\n",
      "k: 9, Train/Test Score: 0.999/0.998\n",
      "k: 11, Train/Test Score: 0.999/0.998\n",
      "k: 13, Train/Test Score: 0.999/0.998\n",
      "k: 15, Train/Test Score: 0.999/0.998\n",
      "k: 17, Train/Test Score: 0.999/0.998\n",
      "k: 19, Train/Test Score: 0.999/0.998\n",
      "Test Acc: 0.998\n",
      "Training Data Score: 0.9986345015930814\n",
      "Testing Data Score: 0.9976109215017065\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled_rf, encoded_y_train)\n",
    "    train_score = knn.score(X_train_scaled_rf, encoded_y_train)\n",
    "    test_score = knn.score(X_test_scaled_rf, encoded_y_test)\n",
    "    #knn.fit(X_train_scaled, encoded_y_train)\n",
    "    #train_score = knn.score(X_train_scaled,encoded_y_train)\n",
    "    #test_score = knn.score(X_test_scaled, encoded_y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "knn.fit(X_train_scaled_rf, encoded_y_train)\n",
    "print('Test Acc: %.3f' % knn.score(X_test_scaled_rf, encoded_y_test))\n",
    "print(f\"Training Data Score: {knn.score(X_train_scaled_rf, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {knn.score(X_test_scaled_rf, encoded_y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Predictions\n",
    "predictions = knn.predict(Xx_test_scaled_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predictions)):\n",
    "    if predictions[i] == 1:\n",
    "        print(i,mvp_2020.iloc[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 8)                 216       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 306\n",
      "Trainable params: 306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8788 samples\n",
      "Epoch 1/1000\n",
      "8788/8788 - 2s - loss: 0.1378 - accuracy: 0.9986\n",
      "Epoch 2/1000\n",
      "8788/8788 - 1s - loss: 0.0186 - accuracy: 0.9986\n",
      "Epoch 3/1000\n",
      "8788/8788 - 0s - loss: 0.0113 - accuracy: 0.9986\n",
      "Epoch 4/1000\n",
      "8788/8788 - 1s - loss: 0.0087 - accuracy: 0.9986\n",
      "Epoch 5/1000\n",
      "8788/8788 - 0s - loss: 0.0079 - accuracy: 0.9986\n",
      "Epoch 6/1000\n",
      "8788/8788 - 1s - loss: 0.0073 - accuracy: 0.9986\n",
      "Epoch 7/1000\n",
      "8788/8788 - 1s - loss: 0.0070 - accuracy: 0.9986\n",
      "Epoch 8/1000\n",
      "8788/8788 - 1s - loss: 0.0065 - accuracy: 0.9986\n",
      "Epoch 9/1000\n",
      "8788/8788 - 1s - loss: 0.0060 - accuracy: 0.9986\n",
      "Epoch 10/1000\n",
      "8788/8788 - 1s - loss: 0.0062 - accuracy: 0.9986\n",
      "Epoch 11/1000\n",
      "8788/8788 - 1s - loss: 0.0058 - accuracy: 0.9986\n",
      "Epoch 12/1000\n",
      "8788/8788 - 1s - loss: 0.0055 - accuracy: 0.9986\n",
      "Epoch 13/1000\n",
      "8788/8788 - 0s - loss: 0.0050 - accuracy: 0.9986\n",
      "Epoch 14/1000\n",
      "8788/8788 - 1s - loss: 0.0056 - accuracy: 0.9986\n",
      "Epoch 15/1000\n",
      "8788/8788 - 0s - loss: 0.0053 - accuracy: 0.9986\n",
      "Epoch 16/1000\n",
      "8788/8788 - 1s - loss: 0.0050 - accuracy: 0.9986\n",
      "Epoch 17/1000\n",
      "8788/8788 - 1s - loss: 0.0052 - accuracy: 0.9986\n",
      "Epoch 18/1000\n",
      "8788/8788 - 1s - loss: 0.0049 - accuracy: 0.9986\n",
      "Epoch 19/1000\n",
      "8788/8788 - 0s - loss: 0.0046 - accuracy: 0.9986\n",
      "Epoch 20/1000\n",
      "8788/8788 - 1s - loss: 0.0048 - accuracy: 0.9986\n",
      "Epoch 21/1000\n",
      "8788/8788 - 0s - loss: 0.0047 - accuracy: 0.9986\n",
      "Epoch 22/1000\n",
      "8788/8788 - 0s - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 23/1000\n",
      "8788/8788 - 0s - loss: 0.0044 - accuracy: 0.9986\n",
      "Epoch 24/1000\n",
      "8788/8788 - 0s - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 25/1000\n",
      "8788/8788 - 1s - loss: 0.0043 - accuracy: 0.9986\n",
      "Epoch 26/1000\n",
      "8788/8788 - 1s - loss: 0.0045 - accuracy: 0.9986\n",
      "Epoch 27/1000\n",
      "8788/8788 - 0s - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 28/1000\n",
      "8788/8788 - 1s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 29/1000\n",
      "8788/8788 - 0s - loss: 0.0045 - accuracy: 0.9986\n",
      "Epoch 30/1000\n",
      "8788/8788 - 1s - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 31/1000\n",
      "8788/8788 - 1s - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 32/1000\n",
      "8788/8788 - 1s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 33/1000\n",
      "8788/8788 - 1s - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 34/1000\n",
      "8788/8788 - 1s - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 35/1000\n",
      "8788/8788 - 1s - loss: 0.0041 - accuracy: 0.9986\n",
      "Epoch 36/1000\n",
      "8788/8788 - 1s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 37/1000\n",
      "8788/8788 - 1s - loss: 0.0034 - accuracy: 0.9986\n",
      "Epoch 38/1000\n",
      "8788/8788 - 1s - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 39/1000\n",
      "8788/8788 - 1s - loss: 0.0035 - accuracy: 0.9986\n",
      "Epoch 40/1000\n",
      "8788/8788 - 1s - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 41/1000\n",
      "8788/8788 - 0s - loss: 0.0046 - accuracy: 0.9986\n",
      "Epoch 42/1000\n",
      "8788/8788 - 0s - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 43/1000\n",
      "8788/8788 - 1s - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 44/1000\n",
      "8788/8788 - 1s - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 45/1000\n",
      "8788/8788 - 1s - loss: 0.0035 - accuracy: 0.9986\n",
      "Epoch 46/1000\n",
      "8788/8788 - 1s - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 47/1000\n",
      "8788/8788 - 1s - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 48/1000\n",
      "8788/8788 - 1s - loss: 0.0035 - accuracy: 0.9986\n",
      "Epoch 49/1000\n",
      "8788/8788 - 1s - loss: 0.0038 - accuracy: 0.9986\n",
      "Epoch 50/1000\n",
      "8788/8788 - 1s - loss: 0.0036 - accuracy: 0.9986\n",
      "Epoch 51/1000\n",
      "8788/8788 - 1s - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 52/1000\n",
      "8788/8788 - 1s - loss: 0.0032 - accuracy: 0.9986\n",
      "Epoch 53/1000\n",
      "8788/8788 - 1s - loss: 0.0035 - accuracy: 0.9986\n",
      "Epoch 54/1000\n",
      "8788/8788 - 1s - loss: 0.0031 - accuracy: 0.9986\n",
      "Epoch 55/1000\n",
      "8788/8788 - 1s - loss: 0.0032 - accuracy: 0.9986\n",
      "Epoch 56/1000\n",
      "8788/8788 - 1s - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 57/1000\n",
      "8788/8788 - 1s - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 58/1000\n",
      "8788/8788 - 0s - loss: 0.0030 - accuracy: 0.9986\n",
      "Epoch 59/1000\n",
      "8788/8788 - 1s - loss: 0.0037 - accuracy: 0.9986\n",
      "Epoch 60/1000\n",
      "8788/8788 - 1s - loss: 0.0032 - accuracy: 0.9986\n",
      "Epoch 61/1000\n",
      "8788/8788 - 1s - loss: 0.0031 - accuracy: 0.9986\n",
      "Epoch 62/1000\n",
      "8788/8788 - 1s - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 63/1000\n",
      "8788/8788 - 1s - loss: 0.0029 - accuracy: 0.9986\n",
      "Epoch 64/1000\n",
      "8788/8788 - 1s - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 65/1000\n",
      "8788/8788 - 1s - loss: 0.0036 - accuracy: 0.9992\n",
      "Epoch 66/1000\n",
      "8788/8788 - 1s - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 67/1000\n",
      "8788/8788 - 1s - loss: 0.0028 - accuracy: 0.9990\n",
      "Epoch 68/1000\n",
      "8788/8788 - 1s - loss: 0.0030 - accuracy: 0.9987\n",
      "Epoch 69/1000\n",
      "8788/8788 - 1s - loss: 0.0031 - accuracy: 0.9989\n",
      "Epoch 70/1000\n",
      "8788/8788 - 1s - loss: 0.0033 - accuracy: 0.9987\n",
      "Epoch 71/1000\n",
      "8788/8788 - 1s - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 72/1000\n",
      "8788/8788 - 1s - loss: 0.0034 - accuracy: 0.9990\n",
      "Epoch 73/1000\n",
      "8788/8788 - 1s - loss: 0.0030 - accuracy: 0.9990\n",
      "Epoch 74/1000\n",
      "8788/8788 - 1s - loss: 0.0028 - accuracy: 0.9992\n",
      "Epoch 75/1000\n",
      "8788/8788 - 1s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 76/1000\n",
      "8788/8788 - 0s - loss: 0.0030 - accuracy: 0.9993\n",
      "Epoch 77/1000\n",
      "8788/8788 - 0s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 78/1000\n",
      "8788/8788 - 1s - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 79/1000\n",
      "8788/8788 - 1s - loss: 0.0024 - accuracy: 0.9989\n",
      "Epoch 80/1000\n",
      "8788/8788 - 1s - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 81/1000\n",
      "8788/8788 - 1s - loss: 0.0028 - accuracy: 0.9989\n",
      "Epoch 82/1000\n",
      "8788/8788 - 1s - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 83/1000\n",
      "8788/8788 - 1s - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 84/1000\n",
      "8788/8788 - 1s - loss: 0.0027 - accuracy: 0.9990\n",
      "Epoch 85/1000\n",
      "8788/8788 - 0s - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 86/1000\n",
      "8788/8788 - 0s - loss: 0.0029 - accuracy: 0.9990\n",
      "Epoch 87/1000\n",
      "8788/8788 - 1s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 88/1000\n",
      "8788/8788 - 1s - loss: 0.0032 - accuracy: 0.9992\n",
      "Epoch 89/1000\n",
      "8788/8788 - 1s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 90/1000\n",
      "8788/8788 - 1s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 91/1000\n",
      "8788/8788 - 1s - loss: 0.0024 - accuracy: 0.9991\n",
      "Epoch 92/1000\n",
      "8788/8788 - 1s - loss: 0.0026 - accuracy: 0.9989\n",
      "Epoch 93/1000\n",
      "8788/8788 - 1s - loss: 0.0026 - accuracy: 0.9992\n",
      "Epoch 94/1000\n",
      "8788/8788 - 0s - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 95/1000\n",
      "8788/8788 - 1s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 96/1000\n",
      "8788/8788 - 1s - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 97/1000\n",
      "8788/8788 - 1s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 98/1000\n",
      "8788/8788 - 1s - loss: 0.0024 - accuracy: 0.9992\n",
      "Epoch 99/1000\n",
      "8788/8788 - 1s - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 100/1000\n",
      "8788/8788 - 1s - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 101/1000\n",
      "8788/8788 - 1s - loss: 0.0031 - accuracy: 0.9992\n",
      "Epoch 102/1000\n",
      "8788/8788 - 1s - loss: 0.0024 - accuracy: 0.9993\n",
      "Epoch 103/1000\n",
      "8788/8788 - 1s - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 104/1000\n",
      "8788/8788 - 1s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 105/1000\n",
      "8788/8788 - 1s - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 106/1000\n",
      "8788/8788 - 1s - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 107/1000\n",
      "8788/8788 - 0s - loss: 0.0024 - accuracy: 0.9995\n",
      "Epoch 108/1000\n",
      "8788/8788 - 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 109/1000\n",
      "8788/8788 - 0s - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 110/1000\n",
      "8788/8788 - 0s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 111/1000\n",
      "8788/8788 - 1s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 112/1000\n",
      "8788/8788 - 1s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 113/1000\n",
      "8788/8788 - 1s - loss: 0.0021 - accuracy: 0.9992\n",
      "Epoch 114/1000\n",
      "8788/8788 - 1s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 115/1000\n",
      "8788/8788 - 1s - loss: 0.0020 - accuracy: 0.9997\n",
      "Epoch 116/1000\n",
      "8788/8788 - 1s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 117/1000\n",
      "8788/8788 - 1s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 118/1000\n",
      "8788/8788 - 1s - loss: 0.0021 - accuracy: 0.9995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/1000\n",
      "8788/8788 - 1s - loss: 0.0035 - accuracy: 0.9991\n",
      "Epoch 120/1000\n",
      "8788/8788 - 1s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 121/1000\n",
      "8788/8788 - 1s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 122/1000\n",
      "8788/8788 - 1s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 123/1000\n",
      "8788/8788 - 1s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 124/1000\n",
      "8788/8788 - 1s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 125/1000\n",
      "8788/8788 - 1s - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 126/1000\n",
      "8788/8788 - 1s - loss: 0.0030 - accuracy: 0.9992\n",
      "Epoch 127/1000\n",
      "8788/8788 - 0s - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 128/1000\n",
      "8788/8788 - 1s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 129/1000\n",
      "8788/8788 - 1s - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 130/1000\n",
      "8788/8788 - 1s - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 131/1000\n",
      "8788/8788 - 1s - loss: 0.0024 - accuracy: 0.9990\n",
      "Epoch 132/1000\n",
      "8788/8788 - 1s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 133/1000\n",
      "8788/8788 - 1s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 134/1000\n",
      "8788/8788 - 1s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 135/1000\n",
      "8788/8788 - 1s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 136/1000\n",
      "8788/8788 - 1s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 137/1000\n",
      "8788/8788 - 1s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 138/1000\n",
      "8788/8788 - 1s - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 139/1000\n",
      "8788/8788 - 1s - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 140/1000\n",
      "8788/8788 - 1s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 141/1000\n",
      "8788/8788 - 1s - loss: 0.0014 - accuracy: 0.9994\n",
      "Epoch 142/1000\n",
      "8788/8788 - 1s - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 143/1000\n",
      "8788/8788 - 0s - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 144/1000\n",
      "8788/8788 - 1s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 145/1000\n",
      "8788/8788 - 1s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 146/1000\n",
      "8788/8788 - 1s - loss: 0.0014 - accuracy: 0.9998\n",
      "Epoch 147/1000\n",
      "8788/8788 - 1s - loss: 0.0017 - accuracy: 0.9995\n",
      "Epoch 148/1000\n",
      "8788/8788 - 1s - loss: 0.0020 - accuracy: 0.9992\n",
      "Epoch 149/1000\n",
      "8788/8788 - 1s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 150/1000\n",
      "8788/8788 - 1s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 151/1000\n",
      "8788/8788 - 1s - loss: 0.0016 - accuracy: 0.9997\n",
      "Epoch 152/1000\n",
      "8788/8788 - 1s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 153/1000\n",
      "8788/8788 - 1s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 154/1000\n",
      "8788/8788 - 0s - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 155/1000\n",
      "8788/8788 - 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 156/1000\n",
      "8788/8788 - 0s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 157/1000\n",
      "8788/8788 - 0s - loss: 0.0019 - accuracy: 0.9991\n",
      "Epoch 158/1000\n",
      "8788/8788 - 0s - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 159/1000\n",
      "8788/8788 - 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 160/1000\n",
      "8788/8788 - 0s - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 161/1000\n",
      "8788/8788 - 0s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 162/1000\n",
      "8788/8788 - 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 163/1000\n",
      "8788/8788 - 0s - loss: 0.0016 - accuracy: 0.9992\n",
      "Epoch 164/1000\n",
      "8788/8788 - 0s - loss: 0.0011 - accuracy: 0.9997\n",
      "Epoch 165/1000\n",
      "8788/8788 - 0s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 166/1000\n",
      "8788/8788 - 0s - loss: 0.0010 - accuracy: 0.9995\n",
      "Epoch 167/1000\n",
      "8788/8788 - 0s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 168/1000\n",
      "8788/8788 - 1s - loss: 0.0010 - accuracy: 0.9999\n",
      "Epoch 169/1000\n",
      "8788/8788 - 1s - loss: 9.7717e-04 - accuracy: 0.9999\n",
      "Epoch 170/1000\n",
      "8788/8788 - 1s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 171/1000\n",
      "8788/8788 - 1s - loss: 0.0015 - accuracy: 0.9998\n",
      "Epoch 172/1000\n",
      "8788/8788 - 1s - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 173/1000\n",
      "8788/8788 - 1s - loss: 0.0010 - accuracy: 0.9995\n",
      "Epoch 174/1000\n",
      "8788/8788 - 1s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 175/1000\n",
      "8788/8788 - 1s - loss: 9.8341e-04 - accuracy: 0.9998\n",
      "Epoch 176/1000\n",
      "8788/8788 - 1s - loss: 9.2991e-04 - accuracy: 0.9998\n",
      "Epoch 177/1000\n",
      "8788/8788 - 1s - loss: 8.8014e-04 - accuracy: 0.9999\n",
      "Epoch 178/1000\n",
      "8788/8788 - 1s - loss: 0.0014 - accuracy: 0.9992\n",
      "Epoch 179/1000\n",
      "8788/8788 - 1s - loss: 0.0017 - accuracy: 0.9992\n",
      "Epoch 180/1000\n",
      "8788/8788 - 1s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 181/1000\n",
      "8788/8788 - 1s - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 182/1000\n",
      "8788/8788 - 1s - loss: 9.3071e-04 - accuracy: 0.9999\n",
      "Epoch 183/1000\n",
      "8788/8788 - 1s - loss: 8.3738e-04 - accuracy: 0.9997\n",
      "Epoch 184/1000\n",
      "8788/8788 - 1s - loss: 8.3817e-04 - accuracy: 0.9999\n",
      "Epoch 185/1000\n",
      "8788/8788 - 1s - loss: 0.0010 - accuracy: 0.9999\n",
      "Epoch 186/1000\n",
      "8788/8788 - 1s - loss: 8.4010e-04 - accuracy: 0.9999\n",
      "Epoch 187/1000\n",
      "8788/8788 - 1s - loss: 0.0014 - accuracy: 0.9994\n",
      "Epoch 188/1000\n",
      "8788/8788 - 1s - loss: 0.0018 - accuracy: 0.9991\n",
      "Epoch 189/1000\n",
      "8788/8788 - 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 190/1000\n",
      "8788/8788 - 0s - loss: 8.6389e-04 - accuracy: 0.9998\n",
      "Epoch 191/1000\n",
      "8788/8788 - 1s - loss: 8.6719e-04 - accuracy: 0.9998\n",
      "Epoch 192/1000\n",
      "8788/8788 - 1s - loss: 9.6235e-04 - accuracy: 0.9995\n",
      "Epoch 193/1000\n",
      "8788/8788 - 1s - loss: 7.5017e-04 - accuracy: 0.9997\n",
      "Epoch 194/1000\n",
      "8788/8788 - 1s - loss: 6.5635e-04 - accuracy: 0.9998\n",
      "Epoch 195/1000\n",
      "8788/8788 - 1s - loss: 6.4678e-04 - accuracy: 0.9999\n",
      "Epoch 196/1000\n",
      "8788/8788 - 1s - loss: 0.0012 - accuracy: 0.9998\n",
      "Epoch 197/1000\n",
      "8788/8788 - 1s - loss: 0.0042 - accuracy: 0.9994\n",
      "Epoch 198/1000\n",
      "8788/8788 - 1s - loss: 8.3314e-04 - accuracy: 0.9998\n",
      "Epoch 199/1000\n",
      "8788/8788 - 1s - loss: 6.6728e-04 - accuracy: 0.9999\n",
      "Epoch 200/1000\n",
      "8788/8788 - 1s - loss: 9.7685e-04 - accuracy: 0.9998\n",
      "Epoch 201/1000\n",
      "8788/8788 - 1s - loss: 7.8560e-04 - accuracy: 0.9998\n",
      "Epoch 202/1000\n",
      "8788/8788 - 1s - loss: 8.8650e-04 - accuracy: 0.9995\n",
      "Epoch 203/1000\n",
      "8788/8788 - 1s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 204/1000\n",
      "8788/8788 - 1s - loss: 6.3322e-04 - accuracy: 0.9998\n",
      "Epoch 205/1000\n",
      "8788/8788 - 1s - loss: 7.2312e-04 - accuracy: 0.9997\n",
      "Epoch 206/1000\n",
      "8788/8788 - 1s - loss: 4.5377e-04 - accuracy: 1.0000\n",
      "Epoch 207/1000\n",
      "8788/8788 - 1s - loss: 7.4843e-04 - accuracy: 0.9998\n",
      "Epoch 208/1000\n",
      "8788/8788 - 1s - loss: 7.8135e-04 - accuracy: 0.9997\n",
      "Epoch 209/1000\n",
      "8788/8788 - 1s - loss: 8.6480e-04 - accuracy: 0.9998\n",
      "Epoch 210/1000\n",
      "8788/8788 - 1s - loss: 4.3772e-04 - accuracy: 1.0000\n",
      "Epoch 211/1000\n",
      "8788/8788 - 1s - loss: 3.5547e-04 - accuracy: 1.0000\n",
      "Epoch 212/1000\n",
      "8788/8788 - 1s - loss: 0.0010 - accuracy: 0.9995\n",
      "Epoch 213/1000\n",
      "8788/8788 - 1s - loss: 0.0019 - accuracy: 0.9998\n",
      "Epoch 214/1000\n",
      "8788/8788 - 1s - loss: 8.1960e-04 - accuracy: 0.9997\n",
      "Epoch 215/1000\n",
      "8788/8788 - 0s - loss: 5.1860e-04 - accuracy: 0.9999\n",
      "Epoch 216/1000\n",
      "8788/8788 - 1s - loss: 4.0216e-04 - accuracy: 0.9999\n",
      "Epoch 217/1000\n",
      "8788/8788 - 1s - loss: 4.9241e-04 - accuracy: 0.9999\n",
      "Epoch 218/1000\n",
      "8788/8788 - 0s - loss: 3.2596e-04 - accuracy: 1.0000\n",
      "Epoch 219/1000\n",
      "8788/8788 - 0s - loss: 4.1545e-04 - accuracy: 1.0000\n",
      "Epoch 220/1000\n",
      "8788/8788 - 0s - loss: 2.5193e-04 - accuracy: 1.0000\n",
      "Epoch 221/1000\n",
      "8788/8788 - 0s - loss: 0.0020 - accuracy: 0.9994\n",
      "Epoch 222/1000\n",
      "8788/8788 - 1s - loss: 4.6726e-04 - accuracy: 0.9999\n",
      "Epoch 223/1000\n",
      "8788/8788 - 1s - loss: 0.0015 - accuracy: 0.9999\n",
      "Epoch 224/1000\n",
      "8788/8788 - 1s - loss: 4.5982e-04 - accuracy: 0.9999\n",
      "Epoch 225/1000\n",
      "8788/8788 - 1s - loss: 3.0689e-04 - accuracy: 1.0000\n",
      "Epoch 226/1000\n",
      "8788/8788 - 1s - loss: 8.6848e-04 - accuracy: 0.9997\n",
      "Epoch 227/1000\n",
      "8788/8788 - 1s - loss: 5.9812e-04 - accuracy: 0.9998\n",
      "Epoch 228/1000\n",
      "8788/8788 - 1s - loss: 3.2701e-04 - accuracy: 1.0000\n",
      "Epoch 229/1000\n",
      "8788/8788 - 1s - loss: 4.2866e-04 - accuracy: 0.9998\n",
      "Epoch 230/1000\n",
      "8788/8788 - 1s - loss: 0.0016 - accuracy: 0.9992\n",
      "Epoch 231/1000\n",
      "8788/8788 - 1s - loss: 5.2519e-04 - accuracy: 0.9999\n",
      "Epoch 232/1000\n",
      "8788/8788 - 1s - loss: 1.9755e-04 - accuracy: 1.0000\n",
      "Epoch 233/1000\n",
      "8788/8788 - 1s - loss: 1.9117e-04 - accuracy: 1.0000\n",
      "Epoch 234/1000\n",
      "8788/8788 - 1s - loss: 1.7588e-04 - accuracy: 1.0000\n",
      "Epoch 235/1000\n",
      "8788/8788 - 1s - loss: 4.6569e-04 - accuracy: 0.9998\n",
      "Epoch 236/1000\n",
      "8788/8788 - 1s - loss: 0.0030 - accuracy: 0.9998\n",
      "Epoch 237/1000\n",
      "8788/8788 - 1s - loss: 5.0026e-04 - accuracy: 0.9999\n",
      "Epoch 238/1000\n",
      "8788/8788 - 1s - loss: 4.6677e-04 - accuracy: 0.9999\n",
      "Epoch 239/1000\n",
      "8788/8788 - 1s - loss: 2.8571e-04 - accuracy: 1.0000\n",
      "Epoch 240/1000\n",
      "8788/8788 - 1s - loss: 1.6548e-04 - accuracy: 1.0000\n",
      "Epoch 241/1000\n",
      "8788/8788 - 1s - loss: 1.9493e-04 - accuracy: 1.0000\n",
      "Epoch 242/1000\n",
      "8788/8788 - 0s - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 243/1000\n",
      "8788/8788 - 1s - loss: 0.0013 - accuracy: 0.9993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 244/1000\n",
      "8788/8788 - 0s - loss: 3.7234e-04 - accuracy: 1.0000\n",
      "Epoch 245/1000\n",
      "8788/8788 - 1s - loss: 1.6204e-04 - accuracy: 1.0000\n",
      "Epoch 246/1000\n",
      "8788/8788 - 0s - loss: 1.6418e-04 - accuracy: 1.0000\n",
      "Epoch 247/1000\n",
      "8788/8788 - 0s - loss: 1.3864e-04 - accuracy: 1.0000\n",
      "Epoch 248/1000\n",
      "8788/8788 - 1s - loss: 3.1125e-04 - accuracy: 1.0000\n",
      "Epoch 249/1000\n",
      "8788/8788 - 1s - loss: 1.5489e-04 - accuracy: 1.0000\n",
      "Epoch 250/1000\n",
      "8788/8788 - 0s - loss: 0.0037 - accuracy: 0.9995\n",
      "Epoch 251/1000\n",
      "8788/8788 - 0s - loss: 0.0020 - accuracy: 0.9998\n",
      "Epoch 252/1000\n",
      "8788/8788 - 0s - loss: 1.5121e-04 - accuracy: 1.0000\n",
      "Epoch 253/1000\n",
      "8788/8788 - 0s - loss: 1.4412e-04 - accuracy: 1.0000\n",
      "Epoch 254/1000\n",
      "8788/8788 - 0s - loss: 1.1968e-04 - accuracy: 1.0000\n",
      "Epoch 255/1000\n",
      "8788/8788 - 1s - loss: 1.1173e-04 - accuracy: 1.0000\n",
      "Epoch 256/1000\n",
      "8788/8788 - 1s - loss: 5.0926e-04 - accuracy: 0.9999\n",
      "Epoch 257/1000\n",
      "8788/8788 - 0s - loss: 2.1897e-04 - accuracy: 1.0000\n",
      "Epoch 258/1000\n",
      "8788/8788 - 0s - loss: 0.0051 - accuracy: 0.9990\n",
      "Epoch 259/1000\n",
      "8788/8788 - 1s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 260/1000\n",
      "8788/8788 - 1s - loss: 1.1754e-04 - accuracy: 1.0000\n",
      "Epoch 261/1000\n",
      "8788/8788 - 0s - loss: 1.1617e-04 - accuracy: 1.0000\n",
      "Epoch 262/1000\n",
      "8788/8788 - 0s - loss: 1.2186e-04 - accuracy: 1.0000\n",
      "Epoch 263/1000\n",
      "8788/8788 - 0s - loss: 1.2144e-04 - accuracy: 1.0000\n",
      "Epoch 264/1000\n",
      "8788/8788 - 1s - loss: 1.0514e-04 - accuracy: 1.0000\n",
      "Epoch 265/1000\n",
      "8788/8788 - 1s - loss: 1.1926e-04 - accuracy: 1.0000\n",
      "Epoch 266/1000\n",
      "8788/8788 - 1s - loss: 1.1163e-04 - accuracy: 1.0000\n",
      "Epoch 267/1000\n",
      "8788/8788 - 1s - loss: 2.0400e-04 - accuracy: 1.0000\n",
      "Epoch 268/1000\n",
      "8788/8788 - 1s - loss: 0.0018 - accuracy: 0.9999\n",
      "Epoch 269/1000\n",
      "8788/8788 - 1s - loss: 2.5475e-04 - accuracy: 0.9999\n",
      "Epoch 270/1000\n",
      "8788/8788 - 1s - loss: 1.3263e-04 - accuracy: 1.0000\n",
      "Epoch 271/1000\n",
      "8788/8788 - 1s - loss: 6.2664e-04 - accuracy: 0.9999\n",
      "Epoch 272/1000\n",
      "8788/8788 - 1s - loss: 9.6008e-04 - accuracy: 0.9995\n",
      "Epoch 273/1000\n",
      "8788/8788 - 1s - loss: 2.1925e-04 - accuracy: 0.9999\n",
      "Epoch 274/1000\n",
      "8788/8788 - 1s - loss: 1.1948e-04 - accuracy: 1.0000\n",
      "Epoch 275/1000\n",
      "8788/8788 - 1s - loss: 1.8746e-04 - accuracy: 1.0000\n",
      "Epoch 276/1000\n",
      "8788/8788 - 0s - loss: 8.2071e-05 - accuracy: 1.0000\n",
      "Epoch 277/1000\n",
      "8788/8788 - 1s - loss: 8.4615e-05 - accuracy: 1.0000\n",
      "Epoch 278/1000\n",
      "8788/8788 - 1s - loss: 1.1808e-04 - accuracy: 1.0000\n",
      "Epoch 279/1000\n",
      "8788/8788 - 1s - loss: 8.1447e-05 - accuracy: 1.0000\n",
      "Epoch 280/1000\n",
      "8788/8788 - 1s - loss: 1.3548e-04 - accuracy: 1.0000\n",
      "Epoch 281/1000\n",
      "8788/8788 - 1s - loss: 8.8271e-05 - accuracy: 1.0000\n",
      "Epoch 282/1000\n",
      "8788/8788 - 1s - loss: 7.4210e-05 - accuracy: 1.0000\n",
      "Epoch 283/1000\n",
      "8788/8788 - 1s - loss: 1.0969e-04 - accuracy: 1.0000\n",
      "Epoch 284/1000\n",
      "8788/8788 - 1s - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 285/1000\n",
      "8788/8788 - 0s - loss: 0.0031 - accuracy: 0.9993\n",
      "Epoch 286/1000\n",
      "8788/8788 - 1s - loss: 1.1299e-04 - accuracy: 1.0000\n",
      "Epoch 287/1000\n",
      "8788/8788 - 1s - loss: 8.6639e-05 - accuracy: 1.0000\n",
      "Epoch 288/1000\n",
      "8788/8788 - 1s - loss: 7.9249e-05 - accuracy: 1.0000\n",
      "Epoch 289/1000\n",
      "8788/8788 - 1s - loss: 7.1817e-05 - accuracy: 1.0000\n",
      "Epoch 290/1000\n",
      "8788/8788 - 1s - loss: 7.0507e-05 - accuracy: 1.0000\n",
      "Epoch 291/1000\n",
      "8788/8788 - 1s - loss: 7.1666e-05 - accuracy: 1.0000\n",
      "Epoch 292/1000\n",
      "8788/8788 - 1s - loss: 6.3945e-05 - accuracy: 1.0000\n",
      "Epoch 293/1000\n",
      "8788/8788 - 1s - loss: 6.6409e-05 - accuracy: 1.0000\n",
      "Epoch 294/1000\n",
      "8788/8788 - 1s - loss: 5.8245e-05 - accuracy: 1.0000\n",
      "Epoch 295/1000\n",
      "8788/8788 - 1s - loss: 1.2479e-04 - accuracy: 1.0000\n",
      "Epoch 296/1000\n",
      "8788/8788 - 1s - loss: 0.0044 - accuracy: 0.9989\n",
      "Epoch 297/1000\n",
      "8788/8788 - 0s - loss: 4.9108e-04 - accuracy: 0.9999\n",
      "Epoch 298/1000\n",
      "8788/8788 - 0s - loss: 1.6312e-04 - accuracy: 1.0000\n",
      "Epoch 299/1000\n",
      "8788/8788 - 1s - loss: 1.1817e-04 - accuracy: 1.0000\n",
      "Epoch 300/1000\n",
      "8788/8788 - 0s - loss: 8.9261e-05 - accuracy: 1.0000\n",
      "Epoch 301/1000\n",
      "8788/8788 - 0s - loss: 8.4678e-05 - accuracy: 1.0000\n",
      "Epoch 302/1000\n",
      "8788/8788 - 1s - loss: 8.5454e-05 - accuracy: 1.0000\n",
      "Epoch 303/1000\n",
      "8788/8788 - 1s - loss: 7.6621e-05 - accuracy: 1.0000\n",
      "Epoch 304/1000\n",
      "8788/8788 - 1s - loss: 7.8677e-05 - accuracy: 1.0000\n",
      "Epoch 305/1000\n",
      "8788/8788 - 1s - loss: 6.8277e-05 - accuracy: 1.0000\n",
      "Epoch 306/1000\n",
      "8788/8788 - 1s - loss: 7.0655e-05 - accuracy: 1.0000\n",
      "Epoch 307/1000\n",
      "8788/8788 - 1s - loss: 1.0192e-04 - accuracy: 1.0000\n",
      "Epoch 308/1000\n",
      "8788/8788 - 0s - loss: 6.2960e-05 - accuracy: 1.0000\n",
      "Epoch 309/1000\n",
      "8788/8788 - 0s - loss: 6.6555e-05 - accuracy: 1.0000\n",
      "Epoch 310/1000\n",
      "8788/8788 - 0s - loss: 2.4242e-04 - accuracy: 0.9999\n",
      "Epoch 311/1000\n",
      "8788/8788 - 0s - loss: 6.0664e-04 - accuracy: 0.9999\n",
      "Epoch 312/1000\n",
      "8788/8788 - 1s - loss: 9.4069e-05 - accuracy: 1.0000\n",
      "Epoch 313/1000\n",
      "8788/8788 - 1s - loss: 4.9640e-05 - accuracy: 1.0000\n",
      "Epoch 314/1000\n",
      "8788/8788 - 1s - loss: 5.1837e-05 - accuracy: 1.0000\n",
      "Epoch 315/1000\n",
      "8788/8788 - 1s - loss: 4.4725e-05 - accuracy: 1.0000\n",
      "Epoch 316/1000\n",
      "8788/8788 - 1s - loss: 4.1973e-05 - accuracy: 1.0000\n",
      "Epoch 317/1000\n",
      "8788/8788 - 1s - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 318/1000\n",
      "8788/8788 - 1s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 319/1000\n",
      "8788/8788 - 1s - loss: 5.8477e-05 - accuracy: 1.0000\n",
      "Epoch 320/1000\n",
      "8788/8788 - 1s - loss: 4.8063e-05 - accuracy: 1.0000\n",
      "Epoch 321/1000\n",
      "8788/8788 - 1s - loss: 4.6019e-05 - accuracy: 1.0000\n",
      "Epoch 322/1000\n",
      "8788/8788 - 1s - loss: 4.2190e-05 - accuracy: 1.0000\n",
      "Epoch 323/1000\n",
      "8788/8788 - 1s - loss: 3.9961e-05 - accuracy: 1.0000\n",
      "Epoch 324/1000\n",
      "8788/8788 - 1s - loss: 4.9253e-05 - accuracy: 1.0000\n",
      "Epoch 325/1000\n",
      "8788/8788 - 1s - loss: 3.8731e-05 - accuracy: 1.0000\n",
      "Epoch 326/1000\n",
      "8788/8788 - 1s - loss: 3.9854e-05 - accuracy: 1.0000\n",
      "Epoch 327/1000\n",
      "8788/8788 - 1s - loss: 3.5174e-05 - accuracy: 1.0000\n",
      "Epoch 328/1000\n",
      "8788/8788 - 1s - loss: 3.5613e-05 - accuracy: 1.0000\n",
      "Epoch 329/1000\n",
      "8788/8788 - 1s - loss: 3.4070e-05 - accuracy: 1.0000\n",
      "Epoch 330/1000\n",
      "8788/8788 - 0s - loss: 0.0011 - accuracy: 0.9998\n",
      "Epoch 331/1000\n",
      "8788/8788 - 0s - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 332/1000\n",
      "8788/8788 - 1s - loss: 2.2283e-04 - accuracy: 0.9999\n",
      "Epoch 333/1000\n",
      "8788/8788 - 1s - loss: 4.6093e-05 - accuracy: 1.0000\n",
      "Epoch 334/1000\n",
      "8788/8788 - 1s - loss: 4.5023e-05 - accuracy: 1.0000\n",
      "Epoch 335/1000\n",
      "8788/8788 - 1s - loss: 4.3077e-05 - accuracy: 1.0000\n",
      "Epoch 336/1000\n",
      "8788/8788 - 1s - loss: 4.2459e-05 - accuracy: 1.0000\n",
      "Epoch 337/1000\n",
      "8788/8788 - 1s - loss: 4.0327e-05 - accuracy: 1.0000\n",
      "Epoch 338/1000\n",
      "8788/8788 - 1s - loss: 4.0466e-05 - accuracy: 1.0000\n",
      "Epoch 339/1000\n",
      "8788/8788 - 1s - loss: 3.9002e-05 - accuracy: 1.0000\n",
      "Epoch 340/1000\n",
      "8788/8788 - 1s - loss: 3.5148e-05 - accuracy: 1.0000\n",
      "Epoch 341/1000\n",
      "8788/8788 - 1s - loss: 3.8350e-05 - accuracy: 1.0000\n",
      "Epoch 342/1000\n",
      "8788/8788 - 1s - loss: 3.8176e-05 - accuracy: 1.0000\n",
      "Epoch 343/1000\n",
      "8788/8788 - 1s - loss: 8.1482e-04 - accuracy: 0.9998\n",
      "Epoch 344/1000\n",
      "8788/8788 - 1s - loss: 3.8201e-05 - accuracy: 1.0000\n",
      "Epoch 345/1000\n",
      "8788/8788 - 1s - loss: 2.8181e-04 - accuracy: 0.9999\n",
      "Epoch 346/1000\n",
      "8788/8788 - 1s - loss: 4.0737e-04 - accuracy: 0.9999\n",
      "Epoch 347/1000\n",
      "8788/8788 - 1s - loss: 9.8777e-05 - accuracy: 1.0000\n",
      "Epoch 348/1000\n",
      "8788/8788 - 1s - loss: 1.6377e-04 - accuracy: 1.0000\n",
      "Epoch 349/1000\n",
      "8788/8788 - 1s - loss: 4.1897e-05 - accuracy: 1.0000\n",
      "Epoch 350/1000\n",
      "8788/8788 - 1s - loss: 2.8369e-05 - accuracy: 1.0000\n",
      "Epoch 351/1000\n",
      "8788/8788 - 0s - loss: 2.7835e-05 - accuracy: 1.0000\n",
      "Epoch 352/1000\n",
      "8788/8788 - 0s - loss: 2.7061e-05 - accuracy: 1.0000\n",
      "Epoch 353/1000\n",
      "8788/8788 - 0s - loss: 2.6915e-05 - accuracy: 1.0000\n",
      "Epoch 354/1000\n",
      "8788/8788 - 1s - loss: 2.6338e-05 - accuracy: 1.0000\n",
      "Epoch 355/1000\n",
      "8788/8788 - 1s - loss: 2.5480e-05 - accuracy: 1.0000\n",
      "Epoch 356/1000\n",
      "8788/8788 - 1s - loss: 2.5418e-05 - accuracy: 1.0000\n",
      "Epoch 357/1000\n",
      "8788/8788 - 1s - loss: 2.9033e-04 - accuracy: 0.9998\n",
      "Epoch 358/1000\n",
      "8788/8788 - 1s - loss: 0.0029 - accuracy: 0.9994\n",
      "Epoch 359/1000\n",
      "8788/8788 - 1s - loss: 4.0974e-05 - accuracy: 1.0000\n",
      "Epoch 360/1000\n",
      "8788/8788 - 1s - loss: 3.8926e-05 - accuracy: 1.0000\n",
      "Epoch 361/1000\n",
      "8788/8788 - 1s - loss: 3.5628e-05 - accuracy: 1.0000\n",
      "Epoch 362/1000\n",
      "8788/8788 - 1s - loss: 3.2639e-05 - accuracy: 1.0000\n",
      "Epoch 363/1000\n",
      "8788/8788 - 1s - loss: 3.0917e-05 - accuracy: 1.0000\n",
      "Epoch 364/1000\n",
      "8788/8788 - 1s - loss: 3.0033e-05 - accuracy: 1.0000\n",
      "Epoch 365/1000\n",
      "8788/8788 - 1s - loss: 2.8163e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366/1000\n",
      "8788/8788 - 1s - loss: 2.6667e-05 - accuracy: 1.0000\n",
      "Epoch 367/1000\n",
      "8788/8788 - 1s - loss: 2.6212e-05 - accuracy: 1.0000\n",
      "Epoch 368/1000\n",
      "8788/8788 - 1s - loss: 2.5834e-05 - accuracy: 1.0000\n",
      "Epoch 369/1000\n",
      "8788/8788 - 1s - loss: 2.5101e-05 - accuracy: 1.0000\n",
      "Epoch 370/1000\n",
      "8788/8788 - 1s - loss: 2.3553e-05 - accuracy: 1.0000\n",
      "Epoch 371/1000\n",
      "8788/8788 - 1s - loss: 2.3825e-05 - accuracy: 1.0000\n",
      "Epoch 372/1000\n",
      "8788/8788 - 1s - loss: 2.2072e-05 - accuracy: 1.0000\n",
      "Epoch 373/1000\n",
      "8788/8788 - 0s - loss: 2.1230e-05 - accuracy: 1.0000\n",
      "Epoch 374/1000\n",
      "8788/8788 - 1s - loss: 2.0573e-05 - accuracy: 1.0000\n",
      "Epoch 375/1000\n",
      "8788/8788 - 1s - loss: 2.0193e-05 - accuracy: 1.0000\n",
      "Epoch 376/1000\n",
      "8788/8788 - 1s - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 377/1000\n",
      "8788/8788 - 1s - loss: 0.0051 - accuracy: 0.9985\n",
      "Epoch 378/1000\n",
      "8788/8788 - 1s - loss: 4.7745e-04 - accuracy: 0.9999\n",
      "Epoch 379/1000\n",
      "8788/8788 - 1s - loss: 1.1808e-04 - accuracy: 1.0000\n",
      "Epoch 380/1000\n",
      "8788/8788 - 1s - loss: 3.3067e-05 - accuracy: 1.0000\n",
      "Epoch 381/1000\n",
      "8788/8788 - 1s - loss: 2.7474e-05 - accuracy: 1.0000\n",
      "Epoch 382/1000\n",
      "8788/8788 - 1s - loss: 2.6890e-05 - accuracy: 1.0000\n",
      "Epoch 383/1000\n",
      "8788/8788 - 1s - loss: 2.5233e-05 - accuracy: 1.0000\n",
      "Epoch 384/1000\n",
      "8788/8788 - 1s - loss: 2.4706e-05 - accuracy: 1.0000\n",
      "Epoch 385/1000\n",
      "8788/8788 - 1s - loss: 2.4174e-05 - accuracy: 1.0000\n",
      "Epoch 386/1000\n",
      "8788/8788 - 1s - loss: 2.4101e-05 - accuracy: 1.0000\n",
      "Epoch 387/1000\n",
      "8788/8788 - 1s - loss: 2.2864e-05 - accuracy: 1.0000\n",
      "Epoch 388/1000\n",
      "8788/8788 - 1s - loss: 2.1573e-05 - accuracy: 1.0000\n",
      "Epoch 389/1000\n",
      "8788/8788 - 1s - loss: 2.2085e-05 - accuracy: 1.0000\n",
      "Epoch 390/1000\n",
      "8788/8788 - 1s - loss: 2.0075e-05 - accuracy: 1.0000\n",
      "Epoch 391/1000\n",
      "8788/8788 - 1s - loss: 1.9989e-05 - accuracy: 1.0000\n",
      "Epoch 392/1000\n",
      "8788/8788 - 1s - loss: 2.1242e-05 - accuracy: 1.0000\n",
      "Epoch 393/1000\n",
      "8788/8788 - 1s - loss: 2.0588e-05 - accuracy: 1.0000\n",
      "Epoch 394/1000\n",
      "8788/8788 - 1s - loss: 1.8386e-05 - accuracy: 1.0000\n",
      "Epoch 395/1000\n",
      "8788/8788 - 1s - loss: 1.9564e-05 - accuracy: 1.0000\n",
      "Epoch 396/1000\n",
      "8788/8788 - 1s - loss: 1.7989e-05 - accuracy: 1.0000\n",
      "Epoch 397/1000\n",
      "8788/8788 - 1s - loss: 2.1230e-05 - accuracy: 1.0000\n",
      "Epoch 398/1000\n",
      "8788/8788 - 1s - loss: 0.0063 - accuracy: 0.9987\n",
      "Epoch 399/1000\n",
      "8788/8788 - 1s - loss: 0.0027 - accuracy: 0.9990\n",
      "Epoch 400/1000\n",
      "8788/8788 - 1s - loss: 0.0014 - accuracy: 0.9993\n",
      "Epoch 401/1000\n",
      "8788/8788 - 1s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 402/1000\n",
      "8788/8788 - 1s - loss: 1.6889e-04 - accuracy: 1.0000\n",
      "Epoch 403/1000\n",
      "8788/8788 - 1s - loss: 4.2971e-05 - accuracy: 1.0000\n",
      "Epoch 404/1000\n",
      "8788/8788 - 1s - loss: 4.2795e-05 - accuracy: 1.0000\n",
      "Epoch 405/1000\n",
      "8788/8788 - 1s - loss: 3.2780e-05 - accuracy: 1.0000\n",
      "Epoch 406/1000\n",
      "8788/8788 - 1s - loss: 2.9578e-05 - accuracy: 1.0000\n",
      "Epoch 407/1000\n",
      "8788/8788 - 1s - loss: 2.6697e-05 - accuracy: 1.0000\n",
      "Epoch 408/1000\n",
      "8788/8788 - 1s - loss: 2.8002e-05 - accuracy: 1.0000\n",
      "Epoch 409/1000\n",
      "8788/8788 - 1s - loss: 2.2578e-05 - accuracy: 1.0000\n",
      "Epoch 410/1000\n",
      "8788/8788 - 1s - loss: 2.5758e-05 - accuracy: 1.0000\n",
      "Epoch 411/1000\n",
      "8788/8788 - 1s - loss: 2.1627e-05 - accuracy: 1.0000\n",
      "Epoch 412/1000\n",
      "8788/8788 - 1s - loss: 2.3223e-05 - accuracy: 1.0000\n",
      "Epoch 413/1000\n",
      "8788/8788 - 1s - loss: 1.8117e-05 - accuracy: 1.0000\n",
      "Epoch 414/1000\n",
      "8788/8788 - 1s - loss: 3.2768e-05 - accuracy: 1.0000\n",
      "Epoch 415/1000\n",
      "8788/8788 - 1s - loss: 3.7710e-04 - accuracy: 0.9999\n",
      "Epoch 416/1000\n",
      "8788/8788 - 1s - loss: 0.0012 - accuracy: 0.9994\n",
      "Epoch 417/1000\n",
      "8788/8788 - 1s - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 418/1000\n",
      "8788/8788 - 1s - loss: 4.2052e-05 - accuracy: 1.0000\n",
      "Epoch 419/1000\n",
      "8788/8788 - 1s - loss: 2.0002e-05 - accuracy: 1.0000\n",
      "Epoch 420/1000\n",
      "8788/8788 - 1s - loss: 1.8778e-05 - accuracy: 1.0000\n",
      "Epoch 421/1000\n",
      "8788/8788 - 0s - loss: 1.7576e-05 - accuracy: 1.0000\n",
      "Epoch 422/1000\n",
      "8788/8788 - 1s - loss: 1.6821e-05 - accuracy: 1.0000\n",
      "Epoch 423/1000\n",
      "8788/8788 - 1s - loss: 1.5894e-05 - accuracy: 1.0000\n",
      "Epoch 424/1000\n",
      "8788/8788 - 1s - loss: 1.4929e-05 - accuracy: 1.0000\n",
      "Epoch 425/1000\n",
      "8788/8788 - 1s - loss: 1.4173e-05 - accuracy: 1.0000\n",
      "Epoch 426/1000\n",
      "8788/8788 - 1s - loss: 1.3672e-05 - accuracy: 1.0000\n",
      "Epoch 427/1000\n",
      "8788/8788 - 0s - loss: 1.2777e-05 - accuracy: 1.0000\n",
      "Epoch 428/1000\n",
      "8788/8788 - 0s - loss: 1.2848e-05 - accuracy: 1.0000\n",
      "Epoch 429/1000\n",
      "8788/8788 - 1s - loss: 1.2946e-05 - accuracy: 1.0000\n",
      "Epoch 430/1000\n",
      "8788/8788 - 1s - loss: 1.2733e-05 - accuracy: 1.0000\n",
      "Epoch 431/1000\n",
      "8788/8788 - 1s - loss: 1.2299e-05 - accuracy: 1.0000\n",
      "Epoch 432/1000\n",
      "8788/8788 - 1s - loss: 1.4556e-05 - accuracy: 1.0000\n",
      "Epoch 433/1000\n",
      "8788/8788 - 1s - loss: 1.1297e-05 - accuracy: 1.0000\n",
      "Epoch 434/1000\n",
      "8788/8788 - 1s - loss: 1.1785e-05 - accuracy: 1.0000\n",
      "Epoch 435/1000\n",
      "8788/8788 - 1s - loss: 1.2117e-05 - accuracy: 1.0000\n",
      "Epoch 436/1000\n",
      "8788/8788 - 1s - loss: 1.0904e-05 - accuracy: 1.0000\n",
      "Epoch 437/1000\n",
      "8788/8788 - 1s - loss: 1.1557e-05 - accuracy: 1.0000\n",
      "Epoch 438/1000\n",
      "8788/8788 - 1s - loss: 1.1415e-05 - accuracy: 1.0000\n",
      "Epoch 439/1000\n",
      "8788/8788 - 1s - loss: 0.0033 - accuracy: 0.9994\n",
      "Epoch 440/1000\n",
      "8788/8788 - 1s - loss: 6.6890e-04 - accuracy: 0.9998\n",
      "Epoch 441/1000\n",
      "8788/8788 - 1s - loss: 5.9752e-05 - accuracy: 1.0000\n",
      "Epoch 442/1000\n",
      "8788/8788 - 1s - loss: 2.5722e-05 - accuracy: 1.0000\n",
      "Epoch 443/1000\n",
      "8788/8788 - 1s - loss: 2.0287e-05 - accuracy: 1.0000\n",
      "Epoch 444/1000\n",
      "8788/8788 - 1s - loss: 1.7668e-05 - accuracy: 1.0000\n",
      "Epoch 445/1000\n",
      "8788/8788 - 1s - loss: 1.6733e-05 - accuracy: 1.0000\n",
      "Epoch 446/1000\n",
      "8788/8788 - 1s - loss: 1.6033e-05 - accuracy: 1.0000\n",
      "Epoch 447/1000\n",
      "8788/8788 - 1s - loss: 1.5557e-05 - accuracy: 1.0000\n",
      "Epoch 448/1000\n",
      "8788/8788 - 0s - loss: 1.4888e-05 - accuracy: 1.0000\n",
      "Epoch 449/1000\n",
      "8788/8788 - 0s - loss: 1.3759e-05 - accuracy: 1.0000\n",
      "Epoch 450/1000\n",
      "8788/8788 - 0s - loss: 1.3564e-05 - accuracy: 1.0000\n",
      "Epoch 451/1000\n",
      "8788/8788 - 1s - loss: 1.2377e-05 - accuracy: 1.0000\n",
      "Epoch 452/1000\n",
      "8788/8788 - 1s - loss: 1.4076e-05 - accuracy: 1.0000\n",
      "Epoch 453/1000\n",
      "8788/8788 - 1s - loss: 1.2090e-05 - accuracy: 1.0000\n",
      "Epoch 454/1000\n",
      "8788/8788 - 1s - loss: 1.2572e-05 - accuracy: 1.0000\n",
      "Epoch 455/1000\n",
      "8788/8788 - 1s - loss: 1.6739e-05 - accuracy: 1.0000\n",
      "Epoch 456/1000\n",
      "8788/8788 - 1s - loss: 1.4709e-05 - accuracy: 1.0000\n",
      "Epoch 457/1000\n",
      "8788/8788 - 1s - loss: 1.0482e-05 - accuracy: 1.0000\n",
      "Epoch 458/1000\n",
      "8788/8788 - 1s - loss: 1.2342e-05 - accuracy: 1.0000\n",
      "Epoch 459/1000\n",
      "8788/8788 - 1s - loss: 3.2561e-04 - accuracy: 0.9998\n",
      "Epoch 460/1000\n",
      "8788/8788 - 1s - loss: 0.0047 - accuracy: 0.9987\n",
      "Epoch 461/1000\n",
      "8788/8788 - 1s - loss: 6.9666e-05 - accuracy: 1.0000\n",
      "Epoch 462/1000\n",
      "8788/8788 - 1s - loss: 2.7965e-05 - accuracy: 1.0000\n",
      "Epoch 463/1000\n",
      "8788/8788 - 1s - loss: 2.2009e-05 - accuracy: 1.0000\n",
      "Epoch 464/1000\n",
      "8788/8788 - 1s - loss: 2.1117e-05 - accuracy: 1.0000\n",
      "Epoch 465/1000\n",
      "8788/8788 - 1s - loss: 1.9209e-05 - accuracy: 1.0000\n",
      "Epoch 466/1000\n",
      "8788/8788 - 1s - loss: 1.8555e-05 - accuracy: 1.0000\n",
      "Epoch 467/1000\n",
      "8788/8788 - 1s - loss: 1.7704e-05 - accuracy: 1.0000\n",
      "Epoch 468/1000\n",
      "8788/8788 - 1s - loss: 1.6518e-05 - accuracy: 1.0000\n",
      "Epoch 469/1000\n",
      "8788/8788 - 1s - loss: 1.6365e-05 - accuracy: 1.0000\n",
      "Epoch 470/1000\n",
      "8788/8788 - 1s - loss: 1.5319e-05 - accuracy: 1.0000\n",
      "Epoch 471/1000\n",
      "8788/8788 - 1s - loss: 1.4551e-05 - accuracy: 1.0000\n",
      "Epoch 472/1000\n",
      "8788/8788 - 1s - loss: 1.4084e-05 - accuracy: 1.0000\n",
      "Epoch 473/1000\n",
      "8788/8788 - 1s - loss: 1.3460e-05 - accuracy: 1.0000\n",
      "Epoch 474/1000\n",
      "8788/8788 - 1s - loss: 1.3228e-05 - accuracy: 1.0000\n",
      "Epoch 475/1000\n",
      "8788/8788 - 1s - loss: 1.2630e-05 - accuracy: 1.0000\n",
      "Epoch 476/1000\n",
      "8788/8788 - 1s - loss: 1.1904e-05 - accuracy: 1.0000\n",
      "Epoch 477/1000\n",
      "8788/8788 - 1s - loss: 1.1952e-05 - accuracy: 1.0000\n",
      "Epoch 478/1000\n",
      "8788/8788 - 1s - loss: 1.1066e-05 - accuracy: 1.0000\n",
      "Epoch 479/1000\n",
      "8788/8788 - 1s - loss: 1.0593e-05 - accuracy: 1.0000\n",
      "Epoch 480/1000\n",
      "8788/8788 - 1s - loss: 1.0967e-05 - accuracy: 1.0000\n",
      "Epoch 481/1000\n",
      "8788/8788 - 1s - loss: 1.1514e-05 - accuracy: 1.0000\n",
      "Epoch 482/1000\n",
      "8788/8788 - 1s - loss: 1.1763e-05 - accuracy: 1.0000\n",
      "Epoch 483/1000\n",
      "8788/8788 - 1s - loss: 9.7308e-06 - accuracy: 1.0000\n",
      "Epoch 484/1000\n",
      "8788/8788 - 1s - loss: 1.0569e-05 - accuracy: 1.0000\n",
      "Epoch 485/1000\n",
      "8788/8788 - 1s - loss: 8.7269e-06 - accuracy: 1.0000\n",
      "Epoch 486/1000\n",
      "8788/8788 - 1s - loss: 4.2845e-05 - accuracy: 1.0000\n",
      "Epoch 487/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788/8788 - 1s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 488/1000\n",
      "8788/8788 - 1s - loss: 7.5188e-04 - accuracy: 0.9997\n",
      "Epoch 489/1000\n",
      "8788/8788 - 1s - loss: 2.2034e-05 - accuracy: 1.0000\n",
      "Epoch 490/1000\n",
      "8788/8788 - 1s - loss: 1.2044e-05 - accuracy: 1.0000\n",
      "Epoch 491/1000\n",
      "8788/8788 - 1s - loss: 1.1146e-05 - accuracy: 1.0000\n",
      "Epoch 492/1000\n",
      "8788/8788 - 1s - loss: 1.0309e-05 - accuracy: 1.0000\n",
      "Epoch 493/1000\n",
      "8788/8788 - 1s - loss: 9.7421e-06 - accuracy: 1.0000\n",
      "Epoch 494/1000\n",
      "8788/8788 - 1s - loss: 9.2824e-06 - accuracy: 1.0000\n",
      "Epoch 495/1000\n",
      "8788/8788 - 1s - loss: 8.9034e-06 - accuracy: 1.0000\n",
      "Epoch 496/1000\n",
      "8788/8788 - 1s - loss: 8.6619e-06 - accuracy: 1.0000\n",
      "Epoch 497/1000\n",
      "8788/8788 - 1s - loss: 8.4647e-06 - accuracy: 1.0000\n",
      "Epoch 498/1000\n",
      "8788/8788 - 1s - loss: 8.1971e-06 - accuracy: 1.0000\n",
      "Epoch 499/1000\n",
      "8788/8788 - 1s - loss: 8.0188e-06 - accuracy: 1.0000\n",
      "Epoch 500/1000\n",
      "8788/8788 - 1s - loss: 8.0061e-06 - accuracy: 1.0000\n",
      "Epoch 501/1000\n",
      "8788/8788 - 1s - loss: 7.7702e-06 - accuracy: 1.0000\n",
      "Epoch 502/1000\n",
      "8788/8788 - 1s - loss: 7.5951e-06 - accuracy: 1.0000\n",
      "Epoch 503/1000\n",
      "8788/8788 - 1s - loss: 7.5553e-06 - accuracy: 1.0000\n",
      "Epoch 504/1000\n",
      "8788/8788 - 1s - loss: 7.2566e-06 - accuracy: 1.0000\n",
      "Epoch 505/1000\n",
      "8788/8788 - 1s - loss: 6.9774e-06 - accuracy: 1.0000\n",
      "Epoch 506/1000\n",
      "8788/8788 - 1s - loss: 7.1251e-06 - accuracy: 1.0000\n",
      "Epoch 507/1000\n",
      "8788/8788 - 1s - loss: 6.7279e-06 - accuracy: 1.0000\n",
      "Epoch 508/1000\n",
      "8788/8788 - 1s - loss: 6.7834e-06 - accuracy: 1.0000\n",
      "Epoch 509/1000\n",
      "8788/8788 - 1s - loss: 6.7262e-06 - accuracy: 1.0000\n",
      "Epoch 510/1000\n",
      "8788/8788 - 1s - loss: 6.5889e-06 - accuracy: 1.0000\n",
      "Epoch 511/1000\n",
      "8788/8788 - 1s - loss: 6.2463e-06 - accuracy: 1.0000\n",
      "Epoch 512/1000\n",
      "8788/8788 - 1s - loss: 6.1364e-06 - accuracy: 1.0000\n",
      "Epoch 513/1000\n",
      "8788/8788 - 1s - loss: 5.7264e-06 - accuracy: 1.0000\n",
      "Epoch 514/1000\n",
      "8788/8788 - 1s - loss: 7.0053e-06 - accuracy: 1.0000\n",
      "Epoch 515/1000\n",
      "8788/8788 - 1s - loss: 5.4323e-06 - accuracy: 1.0000\n",
      "Epoch 516/1000\n",
      "8788/8788 - 1s - loss: 6.2624e-06 - accuracy: 1.0000\n",
      "Epoch 517/1000\n",
      "8788/8788 - 1s - loss: 0.0081 - accuracy: 0.9991\n",
      "Epoch 518/1000\n",
      "8788/8788 - 1s - loss: 7.3375e-04 - accuracy: 0.9998\n",
      "Epoch 519/1000\n",
      "8788/8788 - 1s - loss: 8.8108e-05 - accuracy: 1.0000\n",
      "Epoch 520/1000\n",
      "8788/8788 - 1s - loss: 1.3869e-05 - accuracy: 1.0000\n",
      "Epoch 521/1000\n",
      "8788/8788 - 1s - loss: 9.6593e-06 - accuracy: 1.0000\n",
      "Epoch 522/1000\n",
      "8788/8788 - 1s - loss: 8.6836e-06 - accuracy: 1.0000\n",
      "Epoch 523/1000\n",
      "8788/8788 - 1s - loss: 8.1431e-06 - accuracy: 1.0000\n",
      "Epoch 524/1000\n",
      "8788/8788 - 1s - loss: 7.7862e-06 - accuracy: 1.0000\n",
      "Epoch 525/1000\n",
      "8788/8788 - 1s - loss: 7.5275e-06 - accuracy: 1.0000\n",
      "Epoch 526/1000\n",
      "8788/8788 - 1s - loss: 7.3389e-06 - accuracy: 1.0000\n",
      "Epoch 527/1000\n",
      "8788/8788 - 1s - loss: 7.1854e-06 - accuracy: 1.0000\n",
      "Epoch 528/1000\n",
      "8788/8788 - 0s - loss: 7.0695e-06 - accuracy: 1.0000\n",
      "Epoch 529/1000\n",
      "8788/8788 - 0s - loss: 6.9480e-06 - accuracy: 1.0000\n",
      "Epoch 530/1000\n",
      "8788/8788 - 1s - loss: 6.8239e-06 - accuracy: 1.0000\n",
      "Epoch 531/1000\n",
      "8788/8788 - 1s - loss: 6.7701e-06 - accuracy: 1.0000\n",
      "Epoch 532/1000\n",
      "8788/8788 - 1s - loss: 6.5828e-06 - accuracy: 1.0000\n",
      "Epoch 533/1000\n",
      "8788/8788 - 1s - loss: 6.4600e-06 - accuracy: 1.0000\n",
      "Epoch 534/1000\n",
      "8788/8788 - 1s - loss: 6.3309e-06 - accuracy: 1.0000\n",
      "Epoch 535/1000\n",
      "8788/8788 - 1s - loss: 6.0278e-06 - accuracy: 1.0000\n",
      "Epoch 536/1000\n",
      "8788/8788 - 1s - loss: 5.8925e-06 - accuracy: 1.0000\n",
      "Epoch 537/1000\n",
      "8788/8788 - 1s - loss: 6.0295e-06 - accuracy: 1.0000\n",
      "Epoch 538/1000\n",
      "8788/8788 - 1s - loss: 5.6913e-06 - accuracy: 1.0000\n",
      "Epoch 539/1000\n",
      "8788/8788 - 1s - loss: 5.5128e-06 - accuracy: 1.0000\n",
      "Epoch 540/1000\n",
      "8788/8788 - 1s - loss: 5.5144e-06 - accuracy: 1.0000\n",
      "Epoch 541/1000\n",
      "8788/8788 - 1s - loss: 5.5113e-06 - accuracy: 1.0000\n",
      "Epoch 542/1000\n",
      "8788/8788 - 1s - loss: 5.2796e-06 - accuracy: 1.0000\n",
      "Epoch 543/1000\n",
      "8788/8788 - 1s - loss: 4.9549e-06 - accuracy: 1.0000\n",
      "Epoch 544/1000\n",
      "8788/8788 - 1s - loss: 4.7955e-06 - accuracy: 1.0000\n",
      "Epoch 545/1000\n",
      "8788/8788 - 1s - loss: 5.1728e-06 - accuracy: 1.0000\n",
      "Epoch 546/1000\n",
      "8788/8788 - 1s - loss: 4.7698e-06 - accuracy: 1.0000\n",
      "Epoch 547/1000\n",
      "8788/8788 - 1s - loss: 4.6355e-06 - accuracy: 1.0000\n",
      "Epoch 548/1000\n",
      "8788/8788 - 1s - loss: 4.6557e-06 - accuracy: 1.0000\n",
      "Epoch 549/1000\n",
      "8788/8788 - 1s - loss: 3.9850e-06 - accuracy: 1.0000\n",
      "Epoch 550/1000\n",
      "8788/8788 - 1s - loss: 4.9702e-06 - accuracy: 1.0000\n",
      "Epoch 551/1000\n",
      "8788/8788 - 1s - loss: 0.0031 - accuracy: 0.9997\n",
      "Epoch 552/1000\n",
      "8788/8788 - 1s - loss: 0.0022 - accuracy: 0.9994\n",
      "Epoch 553/1000\n",
      "8788/8788 - 1s - loss: 1.8060e-05 - accuracy: 1.0000\n",
      "Epoch 554/1000\n",
      "8788/8788 - 1s - loss: 1.0779e-05 - accuracy: 1.0000\n",
      "Epoch 555/1000\n",
      "8788/8788 - 1s - loss: 9.4085e-06 - accuracy: 1.0000\n",
      "Epoch 556/1000\n",
      "8788/8788 - 1s - loss: 8.4330e-06 - accuracy: 1.0000\n",
      "Epoch 557/1000\n",
      "8788/8788 - 1s - loss: 7.7468e-06 - accuracy: 1.0000\n",
      "Epoch 558/1000\n",
      "8788/8788 - 1s - loss: 7.1539e-06 - accuracy: 1.0000\n",
      "Epoch 559/1000\n",
      "8788/8788 - 1s - loss: 6.9084e-06 - accuracy: 1.0000\n",
      "Epoch 560/1000\n",
      "8788/8788 - 1s - loss: 6.3467e-06 - accuracy: 1.0000\n",
      "Epoch 561/1000\n",
      "8788/8788 - 1s - loss: 5.9556e-06 - accuracy: 1.0000\n",
      "Epoch 562/1000\n",
      "8788/8788 - 1s - loss: 5.6685e-06 - accuracy: 1.0000\n",
      "Epoch 563/1000\n",
      "8788/8788 - 1s - loss: 5.4394e-06 - accuracy: 1.0000\n",
      "Epoch 564/1000\n",
      "8788/8788 - 1s - loss: 5.1456e-06 - accuracy: 1.0000\n",
      "Epoch 565/1000\n",
      "8788/8788 - 1s - loss: 4.9954e-06 - accuracy: 1.0000\n",
      "Epoch 566/1000\n",
      "8788/8788 - 1s - loss: 4.8514e-06 - accuracy: 1.0000\n",
      "Epoch 567/1000\n",
      "8788/8788 - 1s - loss: 4.6919e-06 - accuracy: 1.0000\n",
      "Epoch 568/1000\n",
      "8788/8788 - 1s - loss: 4.4665e-06 - accuracy: 1.0000\n",
      "Epoch 569/1000\n",
      "8788/8788 - 1s - loss: 4.4708e-06 - accuracy: 1.0000\n",
      "Epoch 570/1000\n",
      "8788/8788 - 1s - loss: 4.2538e-06 - accuracy: 1.0000\n",
      "Epoch 571/1000\n",
      "8788/8788 - 1s - loss: 4.6092e-06 - accuracy: 1.0000\n",
      "Epoch 572/1000\n",
      "8788/8788 - 1s - loss: 4.1619e-06 - accuracy: 1.0000\n",
      "Epoch 573/1000\n",
      "8788/8788 - 1s - loss: 4.4357e-06 - accuracy: 1.0000\n",
      "Epoch 574/1000\n",
      "8788/8788 - 1s - loss: 3.9001e-06 - accuracy: 1.0000\n",
      "Epoch 575/1000\n",
      "8788/8788 - 1s - loss: 3.7650e-06 - accuracy: 1.0000\n",
      "Epoch 576/1000\n",
      "8788/8788 - 1s - loss: 3.5491e-06 - accuracy: 1.0000\n",
      "Epoch 577/1000\n",
      "8788/8788 - 1s - loss: 4.1112e-06 - accuracy: 1.0000\n",
      "Epoch 578/1000\n",
      "8788/8788 - 1s - loss: 3.6817e-06 - accuracy: 1.0000\n",
      "Epoch 579/1000\n",
      "8788/8788 - 1s - loss: 3.3403e-06 - accuracy: 1.0000\n",
      "Epoch 580/1000\n",
      "8788/8788 - 1s - loss: 3.4644e-06 - accuracy: 1.0000\n",
      "Epoch 581/1000\n",
      "8788/8788 - 1s - loss: 3.2149e-06 - accuracy: 1.0000\n",
      "Epoch 582/1000\n",
      "8788/8788 - 1s - loss: 3.6322e-06 - accuracy: 1.0000\n",
      "Epoch 583/1000\n",
      "8788/8788 - 1s - loss: 3.2732e-06 - accuracy: 1.0000\n",
      "Epoch 584/1000\n",
      "8788/8788 - 1s - loss: 0.0033 - accuracy: 0.9997\n",
      "Epoch 585/1000\n",
      "8788/8788 - 1s - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 586/1000\n",
      "8788/8788 - 1s - loss: 1.2373e-05 - accuracy: 1.0000\n",
      "Epoch 587/1000\n",
      "8788/8788 - 1s - loss: 6.1113e-06 - accuracy: 1.0000\n",
      "Epoch 588/1000\n",
      "8788/8788 - 1s - loss: 5.0388e-06 - accuracy: 1.0000\n",
      "Epoch 589/1000\n",
      "8788/8788 - 1s - loss: 4.4928e-06 - accuracy: 1.0000\n",
      "Epoch 590/1000\n",
      "8788/8788 - 1s - loss: 4.1925e-06 - accuracy: 1.0000\n",
      "Epoch 591/1000\n",
      "8788/8788 - 1s - loss: 3.9154e-06 - accuracy: 1.0000\n",
      "Epoch 592/1000\n",
      "8788/8788 - 1s - loss: 3.7885e-06 - accuracy: 1.0000\n",
      "Epoch 593/1000\n",
      "8788/8788 - 0s - loss: 3.6991e-06 - accuracy: 1.0000\n",
      "Epoch 594/1000\n",
      "8788/8788 - 0s - loss: 3.6293e-06 - accuracy: 1.0000\n",
      "Epoch 595/1000\n",
      "8788/8788 - 1s - loss: 3.5395e-06 - accuracy: 1.0000\n",
      "Epoch 596/1000\n",
      "8788/8788 - 1s - loss: 3.4148e-06 - accuracy: 1.0000\n",
      "Epoch 597/1000\n",
      "8788/8788 - 1s - loss: 3.4316e-06 - accuracy: 1.0000\n",
      "Epoch 598/1000\n",
      "8788/8788 - 1s - loss: 3.3526e-06 - accuracy: 1.0000\n",
      "Epoch 599/1000\n",
      "8788/8788 - 1s - loss: 3.2587e-06 - accuracy: 1.0000\n",
      "Epoch 600/1000\n",
      "8788/8788 - 1s - loss: 3.2128e-06 - accuracy: 1.0000\n",
      "Epoch 601/1000\n",
      "8788/8788 - 1s - loss: 3.2110e-06 - accuracy: 1.0000\n",
      "Epoch 602/1000\n",
      "8788/8788 - 1s - loss: 3.0982e-06 - accuracy: 1.0000\n",
      "Epoch 603/1000\n",
      "8788/8788 - 1s - loss: 3.1570e-06 - accuracy: 1.0000\n",
      "Epoch 604/1000\n",
      "8788/8788 - 1s - loss: 3.0668e-06 - accuracy: 1.0000\n",
      "Epoch 605/1000\n",
      "8788/8788 - 1s - loss: 2.9827e-06 - accuracy: 1.0000\n",
      "Epoch 606/1000\n",
      "8788/8788 - 1s - loss: 2.9149e-06 - accuracy: 1.0000\n",
      "Epoch 607/1000\n",
      "8788/8788 - 1s - loss: 2.8726e-06 - accuracy: 1.0000\n",
      "Epoch 608/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788/8788 - 1s - loss: 2.7739e-06 - accuracy: 1.0000\n",
      "Epoch 609/1000\n",
      "8788/8788 - 1s - loss: 2.7158e-06 - accuracy: 1.0000\n",
      "Epoch 610/1000\n",
      "8788/8788 - 1s - loss: 2.7565e-06 - accuracy: 1.0000\n",
      "Epoch 611/1000\n",
      "8788/8788 - 1s - loss: 2.5864e-06 - accuracy: 1.0000\n",
      "Epoch 612/1000\n",
      "8788/8788 - 1s - loss: 2.7143e-06 - accuracy: 1.0000\n",
      "Epoch 613/1000\n",
      "8788/8788 - 1s - loss: 2.6836e-06 - accuracy: 1.0000\n",
      "Epoch 614/1000\n",
      "8788/8788 - 1s - loss: 2.4891e-06 - accuracy: 1.0000\n",
      "Epoch 615/1000\n",
      "8788/8788 - 1s - loss: 2.6301e-06 - accuracy: 1.0000\n",
      "Epoch 616/1000\n",
      "8788/8788 - 1s - loss: 2.5056e-06 - accuracy: 1.0000\n",
      "Epoch 617/1000\n",
      "8788/8788 - 1s - loss: 2.6385e-06 - accuracy: 1.0000\n",
      "Epoch 618/1000\n",
      "8788/8788 - 1s - loss: 2.1436e-06 - accuracy: 1.0000\n",
      "Epoch 619/1000\n",
      "8788/8788 - 1s - loss: 2.5322e-06 - accuracy: 1.0000\n",
      "Epoch 620/1000\n",
      "8788/8788 - 1s - loss: 2.2942e-06 - accuracy: 1.0000\n",
      "Epoch 621/1000\n",
      "8788/8788 - 1s - loss: 2.8174e-06 - accuracy: 1.0000\n",
      "Epoch 622/1000\n",
      "8788/8788 - 1s - loss: 0.0080 - accuracy: 0.9987\n",
      "Epoch 623/1000\n",
      "8788/8788 - 1s - loss: 9.1676e-05 - accuracy: 1.0000\n",
      "Epoch 624/1000\n",
      "8788/8788 - 1s - loss: 6.1829e-06 - accuracy: 1.0000\n",
      "Epoch 625/1000\n",
      "8788/8788 - 1s - loss: 5.4194e-06 - accuracy: 1.0000\n",
      "Epoch 626/1000\n",
      "8788/8788 - 1s - loss: 4.8895e-06 - accuracy: 1.0000\n",
      "Epoch 627/1000\n",
      "8788/8788 - 1s - loss: 4.4822e-06 - accuracy: 1.0000\n",
      "Epoch 628/1000\n",
      "8788/8788 - 1s - loss: 4.1313e-06 - accuracy: 1.0000\n",
      "Epoch 629/1000\n",
      "8788/8788 - 1s - loss: 3.7979e-06 - accuracy: 1.0000\n",
      "Epoch 630/1000\n",
      "8788/8788 - 1s - loss: 3.5611e-06 - accuracy: 1.0000\n",
      "Epoch 631/1000\n",
      "8788/8788 - 1s - loss: 3.3686e-06 - accuracy: 1.0000\n",
      "Epoch 632/1000\n",
      "8788/8788 - 1s - loss: 3.1817e-06 - accuracy: 1.0000\n",
      "Epoch 633/1000\n",
      "8788/8788 - 1s - loss: 3.0752e-06 - accuracy: 1.0000\n",
      "Epoch 634/1000\n",
      "8788/8788 - 0s - loss: 2.9305e-06 - accuracy: 1.0000\n",
      "Epoch 635/1000\n",
      "8788/8788 - 1s - loss: 2.8043e-06 - accuracy: 1.0000\n",
      "Epoch 636/1000\n",
      "8788/8788 - 1s - loss: 2.6709e-06 - accuracy: 1.0000\n",
      "Epoch 637/1000\n",
      "8788/8788 - 1s - loss: 2.6029e-06 - accuracy: 1.0000\n",
      "Epoch 638/1000\n",
      "8788/8788 - 1s - loss: 2.4842e-06 - accuracy: 1.0000\n",
      "Epoch 639/1000\n",
      "8788/8788 - 1s - loss: 2.4429e-06 - accuracy: 1.0000\n",
      "Epoch 640/1000\n",
      "8788/8788 - 1s - loss: 2.3502e-06 - accuracy: 1.0000\n",
      "Epoch 641/1000\n",
      "8788/8788 - 1s - loss: 2.3115e-06 - accuracy: 1.0000\n",
      "Epoch 642/1000\n",
      "8788/8788 - 1s - loss: 2.2808e-06 - accuracy: 1.0000\n",
      "Epoch 643/1000\n",
      "8788/8788 - 1s - loss: 2.2313e-06 - accuracy: 1.0000\n",
      "Epoch 644/1000\n",
      "8788/8788 - 1s - loss: 2.2066e-06 - accuracy: 1.0000\n",
      "Epoch 645/1000\n",
      "8788/8788 - 1s - loss: 2.1141e-06 - accuracy: 1.0000\n",
      "Epoch 646/1000\n",
      "8788/8788 - 1s - loss: 2.0890e-06 - accuracy: 1.0000\n",
      "Epoch 647/1000\n",
      "8788/8788 - 1s - loss: 2.0471e-06 - accuracy: 1.0000\n",
      "Epoch 648/1000\n",
      "8788/8788 - 1s - loss: 2.0507e-06 - accuracy: 1.0000\n",
      "Epoch 649/1000\n",
      "8788/8788 - 1s - loss: 2.0516e-06 - accuracy: 1.0000\n",
      "Epoch 650/1000\n",
      "8788/8788 - 1s - loss: 1.9699e-06 - accuracy: 1.0000\n",
      "Epoch 651/1000\n",
      "8788/8788 - 0s - loss: 1.8681e-06 - accuracy: 1.0000\n",
      "Epoch 652/1000\n",
      "8788/8788 - 1s - loss: 1.9180e-06 - accuracy: 1.0000\n",
      "Epoch 653/1000\n",
      "8788/8788 - 0s - loss: 1.8867e-06 - accuracy: 1.0000\n",
      "Epoch 654/1000\n",
      "8788/8788 - 1s - loss: 1.8563e-06 - accuracy: 1.0000\n",
      "Epoch 655/1000\n",
      "8788/8788 - 1s - loss: 2.2679e-06 - accuracy: 1.0000\n",
      "Epoch 656/1000\n",
      "8788/8788 - 1s - loss: 1.8350e-06 - accuracy: 1.0000\n",
      "Epoch 657/1000\n",
      "8788/8788 - 1s - loss: 1.6860e-06 - accuracy: 1.0000\n",
      "Epoch 658/1000\n",
      "8788/8788 - 1s - loss: 1.6261e-06 - accuracy: 1.0000\n",
      "Epoch 659/1000\n",
      "8788/8788 - 1s - loss: 2.2560e-06 - accuracy: 1.0000\n",
      "Epoch 660/1000\n",
      "8788/8788 - 1s - loss: 0.0067 - accuracy: 0.9990\n",
      "Epoch 661/1000\n",
      "8788/8788 - 1s - loss: 0.0047 - accuracy: 0.9992\n",
      "Epoch 662/1000\n",
      "8788/8788 - 1s - loss: 1.9313e-04 - accuracy: 0.9999\n",
      "Epoch 663/1000\n",
      "8788/8788 - 1s - loss: 1.6538e-05 - accuracy: 1.0000\n",
      "Epoch 664/1000\n",
      "8788/8788 - 1s - loss: 8.2378e-06 - accuracy: 1.0000\n",
      "Epoch 665/1000\n",
      "8788/8788 - 1s - loss: 7.2767e-06 - accuracy: 1.0000\n",
      "Epoch 666/1000\n",
      "8788/8788 - 1s - loss: 6.6106e-06 - accuracy: 1.0000\n",
      "Epoch 667/1000\n",
      "8788/8788 - 1s - loss: 6.0082e-06 - accuracy: 1.0000\n",
      "Epoch 668/1000\n",
      "8788/8788 - 1s - loss: 5.5819e-06 - accuracy: 1.0000\n",
      "Epoch 669/1000\n",
      "8788/8788 - 1s - loss: 5.2891e-06 - accuracy: 1.0000\n",
      "Epoch 670/1000\n",
      "8788/8788 - 1s - loss: 4.9724e-06 - accuracy: 1.0000\n",
      "Epoch 671/1000\n",
      "8788/8788 - 1s - loss: 4.6357e-06 - accuracy: 1.0000\n",
      "Epoch 672/1000\n",
      "8788/8788 - 1s - loss: 4.4437e-06 - accuracy: 1.0000\n",
      "Epoch 673/1000\n",
      "8788/8788 - 1s - loss: 4.1759e-06 - accuracy: 1.0000\n",
      "Epoch 674/1000\n",
      "8788/8788 - 1s - loss: 3.9404e-06 - accuracy: 1.0000\n",
      "Epoch 675/1000\n",
      "8788/8788 - 0s - loss: 3.7323e-06 - accuracy: 1.0000\n",
      "Epoch 676/1000\n",
      "8788/8788 - 0s - loss: 3.5501e-06 - accuracy: 1.0000\n",
      "Epoch 677/1000\n",
      "8788/8788 - 1s - loss: 3.3970e-06 - accuracy: 1.0000\n",
      "Epoch 678/1000\n",
      "8788/8788 - 1s - loss: 3.1800e-06 - accuracy: 1.0000\n",
      "Epoch 679/1000\n",
      "8788/8788 - 1s - loss: 3.0579e-06 - accuracy: 1.0000\n",
      "Epoch 680/1000\n",
      "8788/8788 - 0s - loss: 2.9557e-06 - accuracy: 1.0000\n",
      "Epoch 681/1000\n",
      "8788/8788 - 1s - loss: 2.8799e-06 - accuracy: 1.0000\n",
      "Epoch 682/1000\n",
      "8788/8788 - 1s - loss: 2.7204e-06 - accuracy: 1.0000\n",
      "Epoch 683/1000\n",
      "8788/8788 - 1s - loss: 2.6064e-06 - accuracy: 1.0000\n",
      "Epoch 684/1000\n",
      "8788/8788 - 0s - loss: 2.4983e-06 - accuracy: 1.0000\n",
      "Epoch 685/1000\n",
      "8788/8788 - 0s - loss: 2.4070e-06 - accuracy: 1.0000\n",
      "Epoch 686/1000\n",
      "8788/8788 - 0s - loss: 2.3443e-06 - accuracy: 1.0000\n",
      "Epoch 687/1000\n",
      "8788/8788 - 0s - loss: 2.1968e-06 - accuracy: 1.0000\n",
      "Epoch 688/1000\n",
      "8788/8788 - 0s - loss: 2.1975e-06 - accuracy: 1.0000\n",
      "Epoch 689/1000\n",
      "8788/8788 - 0s - loss: 2.1610e-06 - accuracy: 1.0000\n",
      "Epoch 690/1000\n",
      "8788/8788 - 1s - loss: 2.0929e-06 - accuracy: 1.0000\n",
      "Epoch 691/1000\n",
      "8788/8788 - 1s - loss: 2.0230e-06 - accuracy: 1.0000\n",
      "Epoch 692/1000\n",
      "8788/8788 - 0s - loss: 2.0998e-06 - accuracy: 1.0000\n",
      "Epoch 693/1000\n",
      "8788/8788 - 0s - loss: 2.1017e-06 - accuracy: 1.0000\n",
      "Epoch 694/1000\n",
      "8788/8788 - 1s - loss: 5.9947e-04 - accuracy: 0.9998\n",
      "Epoch 695/1000\n",
      "8788/8788 - 1s - loss: 6.3605e-04 - accuracy: 0.9999\n",
      "Epoch 696/1000\n",
      "8788/8788 - 1s - loss: 1.6224e-05 - accuracy: 1.0000\n",
      "Epoch 697/1000\n",
      "8788/8788 - 0s - loss: 6.2629e-06 - accuracy: 1.0000\n",
      "Epoch 698/1000\n",
      "8788/8788 - 0s - loss: 4.3005e-06 - accuracy: 1.0000\n",
      "Epoch 699/1000\n",
      "8788/8788 - 1s - loss: 3.9450e-06 - accuracy: 1.0000\n",
      "Epoch 700/1000\n",
      "8788/8788 - 1s - loss: 3.8493e-06 - accuracy: 1.0000\n",
      "Epoch 701/1000\n",
      "8788/8788 - 1s - loss: 3.5574e-06 - accuracy: 1.0000\n",
      "Epoch 702/1000\n",
      "8788/8788 - 1s - loss: 3.0580e-06 - accuracy: 1.0000\n",
      "Epoch 703/1000\n",
      "8788/8788 - 1s - loss: 2.8189e-06 - accuracy: 1.0000\n",
      "Epoch 704/1000\n",
      "8788/8788 - 1s - loss: 2.6362e-06 - accuracy: 1.0000\n",
      "Epoch 705/1000\n",
      "8788/8788 - 1s - loss: 2.3687e-06 - accuracy: 1.0000\n",
      "Epoch 706/1000\n",
      "8788/8788 - 1s - loss: 2.2521e-06 - accuracy: 1.0000\n",
      "Epoch 707/1000\n",
      "8788/8788 - 1s - loss: 2.0777e-06 - accuracy: 1.0000\n",
      "Epoch 708/1000\n",
      "8788/8788 - 1s - loss: 1.9502e-06 - accuracy: 1.0000\n",
      "Epoch 709/1000\n",
      "8788/8788 - 1s - loss: 1.8450e-06 - accuracy: 1.0000\n",
      "Epoch 710/1000\n",
      "8788/8788 - 1s - loss: 1.7183e-06 - accuracy: 1.0000\n",
      "Epoch 711/1000\n",
      "8788/8788 - 1s - loss: 1.6702e-06 - accuracy: 1.0000\n",
      "Epoch 712/1000\n",
      "8788/8788 - 1s - loss: 1.5666e-06 - accuracy: 1.0000\n",
      "Epoch 713/1000\n",
      "8788/8788 - 1s - loss: 1.5429e-06 - accuracy: 1.0000\n",
      "Epoch 714/1000\n",
      "8788/8788 - 1s - loss: 1.4938e-06 - accuracy: 1.0000\n",
      "Epoch 715/1000\n",
      "8788/8788 - 1s - loss: 1.4044e-06 - accuracy: 1.0000\n",
      "Epoch 716/1000\n",
      "8788/8788 - 1s - loss: 1.3613e-06 - accuracy: 1.0000\n",
      "Epoch 717/1000\n",
      "8788/8788 - 1s - loss: 1.3096e-06 - accuracy: 1.0000\n",
      "Epoch 718/1000\n",
      "8788/8788 - 0s - loss: 1.3308e-06 - accuracy: 1.0000\n",
      "Epoch 719/1000\n",
      "8788/8788 - 0s - loss: 1.2872e-06 - accuracy: 1.0000\n",
      "Epoch 720/1000\n",
      "8788/8788 - 0s - loss: 1.2998e-06 - accuracy: 1.0000\n",
      "Epoch 721/1000\n",
      "8788/8788 - 0s - loss: 1.2460e-06 - accuracy: 1.0000\n",
      "Epoch 722/1000\n",
      "8788/8788 - 0s - loss: 1.2379e-06 - accuracy: 1.0000\n",
      "Epoch 723/1000\n",
      "8788/8788 - 0s - loss: 1.2119e-06 - accuracy: 1.0000\n",
      "Epoch 724/1000\n",
      "8788/8788 - 0s - loss: 1.7591e-06 - accuracy: 1.0000\n",
      "Epoch 725/1000\n",
      "8788/8788 - 0s - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 726/1000\n",
      "8788/8788 - 0s - loss: 0.0041 - accuracy: 0.9995\n",
      "Epoch 727/1000\n",
      "8788/8788 - 0s - loss: 0.0016 - accuracy: 0.9998\n",
      "Epoch 728/1000\n",
      "8788/8788 - 0s - loss: 1.6182e-05 - accuracy: 1.0000\n",
      "Epoch 729/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788/8788 - 0s - loss: 5.8559e-06 - accuracy: 1.0000\n",
      "Epoch 730/1000\n",
      "8788/8788 - 0s - loss: 4.7509e-06 - accuracy: 1.0000\n",
      "Epoch 731/1000\n",
      "8788/8788 - 0s - loss: 3.9934e-06 - accuracy: 1.0000\n",
      "Epoch 732/1000\n",
      "8788/8788 - 0s - loss: 3.2217e-06 - accuracy: 1.0000\n",
      "Epoch 733/1000\n",
      "8788/8788 - 0s - loss: 2.7085e-06 - accuracy: 1.0000\n",
      "Epoch 734/1000\n",
      "8788/8788 - 0s - loss: 2.4165e-06 - accuracy: 1.0000\n",
      "Epoch 735/1000\n",
      "8788/8788 - 0s - loss: 2.1609e-06 - accuracy: 1.0000\n",
      "Epoch 736/1000\n",
      "8788/8788 - 0s - loss: 1.9919e-06 - accuracy: 1.0000\n",
      "Epoch 737/1000\n",
      "8788/8788 - 0s - loss: 1.8825e-06 - accuracy: 1.0000\n",
      "Epoch 738/1000\n",
      "8788/8788 - 0s - loss: 1.7823e-06 - accuracy: 1.0000\n",
      "Epoch 739/1000\n",
      "8788/8788 - 0s - loss: 1.7009e-06 - accuracy: 1.0000\n",
      "Epoch 740/1000\n",
      "8788/8788 - 0s - loss: 1.6421e-06 - accuracy: 1.0000\n",
      "Epoch 741/1000\n",
      "8788/8788 - 0s - loss: 1.5797e-06 - accuracy: 1.0000\n",
      "Epoch 742/1000\n",
      "8788/8788 - 0s - loss: 1.5213e-06 - accuracy: 1.0000\n",
      "Epoch 743/1000\n",
      "8788/8788 - 0s - loss: 1.4777e-06 - accuracy: 1.0000\n",
      "Epoch 744/1000\n",
      "8788/8788 - 0s - loss: 1.4412e-06 - accuracy: 1.0000\n",
      "Epoch 745/1000\n",
      "8788/8788 - 0s - loss: 1.4015e-06 - accuracy: 1.0000\n",
      "Epoch 746/1000\n",
      "8788/8788 - 0s - loss: 1.3639e-06 - accuracy: 1.0000\n",
      "Epoch 747/1000\n",
      "8788/8788 - 0s - loss: 1.3389e-06 - accuracy: 1.0000\n",
      "Epoch 748/1000\n",
      "8788/8788 - 0s - loss: 1.3093e-06 - accuracy: 1.0000\n",
      "Epoch 749/1000\n",
      "8788/8788 - 0s - loss: 1.2852e-06 - accuracy: 1.0000\n",
      "Epoch 750/1000\n",
      "8788/8788 - 0s - loss: 1.2636e-06 - accuracy: 1.0000\n",
      "Epoch 751/1000\n",
      "8788/8788 - 0s - loss: 1.2262e-06 - accuracy: 1.0000\n",
      "Epoch 752/1000\n",
      "8788/8788 - 0s - loss: 1.2372e-06 - accuracy: 1.0000\n",
      "Epoch 753/1000\n",
      "8788/8788 - 1s - loss: 1.1823e-06 - accuracy: 1.0000\n",
      "Epoch 754/1000\n",
      "8788/8788 - 1s - loss: 1.1893e-06 - accuracy: 1.0000\n",
      "Epoch 755/1000\n",
      "8788/8788 - 0s - loss: 1.1752e-06 - accuracy: 1.0000\n",
      "Epoch 756/1000\n",
      "8788/8788 - 0s - loss: 1.1295e-06 - accuracy: 1.0000\n",
      "Epoch 757/1000\n",
      "8788/8788 - 1s - loss: 1.1052e-06 - accuracy: 1.0000\n",
      "Epoch 758/1000\n",
      "8788/8788 - 1s - loss: 1.0687e-06 - accuracy: 1.0000\n",
      "Epoch 759/1000\n",
      "8788/8788 - 0s - loss: 1.0359e-06 - accuracy: 1.0000\n",
      "Epoch 760/1000\n",
      "8788/8788 - 0s - loss: 9.9578e-07 - accuracy: 1.0000\n",
      "Epoch 761/1000\n",
      "8788/8788 - 0s - loss: 9.6931e-07 - accuracy: 1.0000\n",
      "Epoch 762/1000\n",
      "8788/8788 - 0s - loss: 9.2589e-07 - accuracy: 1.0000\n",
      "Epoch 763/1000\n",
      "8788/8788 - 0s - loss: 9.3028e-07 - accuracy: 1.0000\n",
      "Epoch 764/1000\n",
      "8788/8788 - 0s - loss: 8.6765e-07 - accuracy: 1.0000\n",
      "Epoch 765/1000\n",
      "8788/8788 - 0s - loss: 8.7651e-07 - accuracy: 1.0000\n",
      "Epoch 766/1000\n",
      "8788/8788 - 0s - loss: 8.3304e-07 - accuracy: 1.0000\n",
      "Epoch 767/1000\n",
      "8788/8788 - 0s - loss: 7.7174e-07 - accuracy: 1.0000\n",
      "Epoch 768/1000\n",
      "8788/8788 - 0s - loss: 7.3977e-07 - accuracy: 1.0000\n",
      "Epoch 769/1000\n",
      "8788/8788 - 0s - loss: 7.2136e-07 - accuracy: 1.0000\n",
      "Epoch 770/1000\n",
      "8788/8788 - 0s - loss: 6.9911e-07 - accuracy: 1.0000\n",
      "Epoch 771/1000\n",
      "8788/8788 - 0s - loss: 1.0496e-06 - accuracy: 1.0000\n",
      "Epoch 772/1000\n",
      "8788/8788 - 0s - loss: 0.0037 - accuracy: 0.9997\n",
      "Epoch 773/1000\n",
      "8788/8788 - 0s - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 774/1000\n",
      "8788/8788 - 0s - loss: 7.3345e-05 - accuracy: 1.0000\n",
      "Epoch 775/1000\n",
      "8788/8788 - 0s - loss: 2.5359e-05 - accuracy: 1.0000\n",
      "Epoch 776/1000\n",
      "8788/8788 - 0s - loss: 2.0215e-05 - accuracy: 1.0000\n",
      "Epoch 777/1000\n",
      "8788/8788 - 0s - loss: 1.2717e-05 - accuracy: 1.0000\n",
      "Epoch 778/1000\n",
      "8788/8788 - 0s - loss: 1.0264e-05 - accuracy: 1.0000\n",
      "Epoch 779/1000\n",
      "8788/8788 - 0s - loss: 8.8516e-06 - accuracy: 1.0000\n",
      "Epoch 780/1000\n",
      "8788/8788 - 0s - loss: 7.7193e-06 - accuracy: 1.0000\n",
      "Epoch 781/1000\n",
      "8788/8788 - 0s - loss: 6.7978e-06 - accuracy: 1.0000\n",
      "Epoch 782/1000\n",
      "8788/8788 - 0s - loss: 6.0155e-06 - accuracy: 1.0000\n",
      "Epoch 783/1000\n",
      "8788/8788 - 0s - loss: 5.2794e-06 - accuracy: 1.0000\n",
      "Epoch 784/1000\n",
      "8788/8788 - 0s - loss: 4.5409e-06 - accuracy: 1.0000\n",
      "Epoch 785/1000\n",
      "8788/8788 - 0s - loss: 4.0947e-06 - accuracy: 1.0000\n",
      "Epoch 786/1000\n",
      "8788/8788 - 0s - loss: 3.6671e-06 - accuracy: 1.0000\n",
      "Epoch 787/1000\n",
      "8788/8788 - 0s - loss: 3.3031e-06 - accuracy: 1.0000\n",
      "Epoch 788/1000\n",
      "8788/8788 - 0s - loss: 2.9434e-06 - accuracy: 1.0000\n",
      "Epoch 789/1000\n",
      "8788/8788 - 0s - loss: 2.7580e-06 - accuracy: 1.0000\n",
      "Epoch 790/1000\n",
      "8788/8788 - 0s - loss: 2.4384e-06 - accuracy: 1.0000\n",
      "Epoch 791/1000\n",
      "8788/8788 - 0s - loss: 2.0385e-06 - accuracy: 1.0000\n",
      "Epoch 792/1000\n",
      "8788/8788 - 0s - loss: 1.8551e-06 - accuracy: 1.0000\n",
      "Epoch 793/1000\n",
      "8788/8788 - 0s - loss: 1.6810e-06 - accuracy: 1.0000\n",
      "Epoch 794/1000\n",
      "8788/8788 - 0s - loss: 1.5679e-06 - accuracy: 1.0000\n",
      "Epoch 795/1000\n",
      "8788/8788 - 0s - loss: 1.4496e-06 - accuracy: 1.0000\n",
      "Epoch 796/1000\n",
      "8788/8788 - 0s - loss: 1.3667e-06 - accuracy: 1.0000\n",
      "Epoch 797/1000\n",
      "8788/8788 - 0s - loss: 1.1918e-06 - accuracy: 1.0000\n",
      "Epoch 798/1000\n",
      "8788/8788 - 0s - loss: 1.1334e-06 - accuracy: 1.0000\n",
      "Epoch 799/1000\n",
      "8788/8788 - 0s - loss: 1.0857e-06 - accuracy: 1.0000\n",
      "Epoch 800/1000\n",
      "8788/8788 - 0s - loss: 1.0695e-06 - accuracy: 1.0000\n",
      "Epoch 801/1000\n",
      "8788/8788 - 0s - loss: 9.5613e-07 - accuracy: 1.0000\n",
      "Epoch 802/1000\n",
      "8788/8788 - 0s - loss: 9.3648e-07 - accuracy: 1.0000\n",
      "Epoch 803/1000\n",
      "8788/8788 - 0s - loss: 9.2970e-07 - accuracy: 1.0000\n",
      "Epoch 804/1000\n",
      "8788/8788 - 0s - loss: 8.3456e-07 - accuracy: 1.0000\n",
      "Epoch 805/1000\n",
      "8788/8788 - 0s - loss: 8.3199e-07 - accuracy: 1.0000\n",
      "Epoch 806/1000\n",
      "8788/8788 - 0s - loss: 7.1616e-07 - accuracy: 1.0000\n",
      "Epoch 807/1000\n",
      "8788/8788 - 0s - loss: 8.8971e-07 - accuracy: 1.0000\n",
      "Epoch 808/1000\n",
      "8788/8788 - 0s - loss: 7.7861e-07 - accuracy: 1.0000\n",
      "Epoch 809/1000\n",
      "8788/8788 - 0s - loss: 7.1887e-07 - accuracy: 1.0000\n",
      "Epoch 810/1000\n",
      "8788/8788 - 0s - loss: 5.9234e-07 - accuracy: 1.0000\n",
      "Epoch 811/1000\n",
      "8788/8788 - 0s - loss: 6.9260e-07 - accuracy: 1.0000\n",
      "Epoch 812/1000\n",
      "8788/8788 - 0s - loss: 6.1239e-07 - accuracy: 1.0000\n",
      "Epoch 813/1000\n",
      "8788/8788 - 1s - loss: 5.8081e-07 - accuracy: 1.0000\n",
      "Epoch 814/1000\n",
      "8788/8788 - 0s - loss: 5.3483e-07 - accuracy: 1.0000\n",
      "Epoch 815/1000\n",
      "8788/8788 - 0s - loss: 7.1192e-07 - accuracy: 1.0000\n",
      "Epoch 816/1000\n",
      "8788/8788 - 0s - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 817/1000\n",
      "8788/8788 - 0s - loss: 0.0019 - accuracy: 0.9992\n",
      "Epoch 818/1000\n",
      "8788/8788 - 0s - loss: 2.1139e-04 - accuracy: 0.9999\n",
      "Epoch 819/1000\n",
      "8788/8788 - 0s - loss: 7.8180e-06 - accuracy: 1.0000\n",
      "Epoch 820/1000\n",
      "8788/8788 - 0s - loss: 3.7785e-06 - accuracy: 1.0000\n",
      "Epoch 821/1000\n",
      "8788/8788 - 0s - loss: 2.9635e-06 - accuracy: 1.0000\n",
      "Epoch 822/1000\n",
      "8788/8788 - 0s - loss: 2.3998e-06 - accuracy: 1.0000\n",
      "Epoch 823/1000\n",
      "8788/8788 - 0s - loss: 2.0952e-06 - accuracy: 1.0000\n",
      "Epoch 824/1000\n",
      "8788/8788 - 0s - loss: 1.7676e-06 - accuracy: 1.0000\n",
      "Epoch 825/1000\n",
      "8788/8788 - 0s - loss: 1.5814e-06 - accuracy: 1.0000\n",
      "Epoch 826/1000\n",
      "8788/8788 - 0s - loss: 1.4182e-06 - accuracy: 1.0000\n",
      "Epoch 827/1000\n",
      "8788/8788 - 0s - loss: 1.2819e-06 - accuracy: 1.0000\n",
      "Epoch 828/1000\n",
      "8788/8788 - 0s - loss: 1.1825e-06 - accuracy: 1.0000\n",
      "Epoch 829/1000\n",
      "8788/8788 - 0s - loss: 1.0879e-06 - accuracy: 1.0000\n",
      "Epoch 830/1000\n",
      "8788/8788 - 0s - loss: 1.0316e-06 - accuracy: 1.0000\n",
      "Epoch 831/1000\n",
      "8788/8788 - 0s - loss: 9.5337e-07 - accuracy: 1.0000\n",
      "Epoch 832/1000\n",
      "8788/8788 - 0s - loss: 9.0148e-07 - accuracy: 1.0000\n",
      "Epoch 833/1000\n",
      "8788/8788 - 0s - loss: 8.5143e-07 - accuracy: 1.0000\n",
      "Epoch 834/1000\n",
      "8788/8788 - 1s - loss: 8.2082e-07 - accuracy: 1.0000\n",
      "Epoch 835/1000\n",
      "8788/8788 - 0s - loss: 7.8864e-07 - accuracy: 1.0000\n",
      "Epoch 836/1000\n",
      "8788/8788 - 1s - loss: 7.6435e-07 - accuracy: 1.0000\n",
      "Epoch 837/1000\n",
      "8788/8788 - 1s - loss: 7.5861e-07 - accuracy: 1.0000\n",
      "Epoch 838/1000\n",
      "8788/8788 - 1s - loss: 7.4101e-07 - accuracy: 1.0000\n",
      "Epoch 839/1000\n",
      "8788/8788 - 1s - loss: 7.2755e-07 - accuracy: 1.0000\n",
      "Epoch 840/1000\n",
      "8788/8788 - 1s - loss: 7.1385e-07 - accuracy: 1.0000\n",
      "Epoch 841/1000\n",
      "8788/8788 - 0s - loss: 7.0838e-07 - accuracy: 1.0000\n",
      "Epoch 842/1000\n",
      "8788/8788 - 0s - loss: 7.1116e-07 - accuracy: 1.0000\n",
      "Epoch 843/1000\n",
      "8788/8788 - 0s - loss: 6.8837e-07 - accuracy: 1.0000\n",
      "Epoch 844/1000\n",
      "8788/8788 - 0s - loss: 6.7900e-07 - accuracy: 1.0000\n",
      "Epoch 845/1000\n",
      "8788/8788 - 0s - loss: 6.6227e-07 - accuracy: 1.0000\n",
      "Epoch 846/1000\n",
      "8788/8788 - 0s - loss: 6.5399e-07 - accuracy: 1.0000\n",
      "Epoch 847/1000\n",
      "8788/8788 - 1s - loss: 6.4075e-07 - accuracy: 1.0000\n",
      "Epoch 848/1000\n",
      "8788/8788 - 1s - loss: 6.3002e-07 - accuracy: 1.0000\n",
      "Epoch 849/1000\n",
      "8788/8788 - 1s - loss: 6.1691e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 850/1000\n",
      "8788/8788 - 1s - loss: 5.9668e-07 - accuracy: 1.0000\n",
      "Epoch 851/1000\n",
      "8788/8788 - 0s - loss: 5.8960e-07 - accuracy: 1.0000\n",
      "Epoch 852/1000\n",
      "8788/8788 - 0s - loss: 5.6850e-07 - accuracy: 1.0000\n",
      "Epoch 853/1000\n",
      "8788/8788 - 0s - loss: 5.5374e-07 - accuracy: 1.0000\n",
      "Epoch 854/1000\n",
      "8788/8788 - 0s - loss: 5.5522e-07 - accuracy: 1.0000\n",
      "Epoch 855/1000\n",
      "8788/8788 - 0s - loss: 5.2069e-07 - accuracy: 1.0000\n",
      "Epoch 856/1000\n",
      "8788/8788 - 0s - loss: 5.1368e-07 - accuracy: 1.0000\n",
      "Epoch 857/1000\n",
      "8788/8788 - 0s - loss: 1.0122e-06 - accuracy: 1.0000\n",
      "Epoch 858/1000\n",
      "8788/8788 - 0s - loss: 8.6659e-07 - accuracy: 1.0000\n",
      "Epoch 859/1000\n",
      "8788/8788 - 1s - loss: 0.0056 - accuracy: 0.9992\n",
      "Epoch 860/1000\n",
      "8788/8788 - 1s - loss: 0.0027 - accuracy: 0.9992\n",
      "Epoch 861/1000\n",
      "8788/8788 - 0s - loss: 1.3119e-05 - accuracy: 1.0000\n",
      "Epoch 862/1000\n",
      "8788/8788 - 0s - loss: 3.5498e-06 - accuracy: 1.0000\n",
      "Epoch 863/1000\n",
      "8788/8788 - 0s - loss: 2.7719e-06 - accuracy: 1.0000\n",
      "Epoch 864/1000\n",
      "8788/8788 - 0s - loss: 2.3501e-06 - accuracy: 1.0000\n",
      "Epoch 865/1000\n",
      "8788/8788 - 0s - loss: 2.0841e-06 - accuracy: 1.0000\n",
      "Epoch 866/1000\n",
      "8788/8788 - 0s - loss: 1.8995e-06 - accuracy: 1.0000\n",
      "Epoch 867/1000\n",
      "8788/8788 - 0s - loss: 1.7590e-06 - accuracy: 1.0000\n",
      "Epoch 868/1000\n",
      "8788/8788 - 0s - loss: 1.6451e-06 - accuracy: 1.0000\n",
      "Epoch 869/1000\n",
      "8788/8788 - 0s - loss: 1.5213e-06 - accuracy: 1.0000\n",
      "Epoch 870/1000\n",
      "8788/8788 - 0s - loss: 1.4365e-06 - accuracy: 1.0000\n",
      "Epoch 871/1000\n",
      "8788/8788 - 1s - loss: 1.3324e-06 - accuracy: 1.0000\n",
      "Epoch 872/1000\n",
      "8788/8788 - 1s - loss: 1.2499e-06 - accuracy: 1.0000\n",
      "Epoch 873/1000\n",
      "8788/8788 - 0s - loss: 1.2107e-06 - accuracy: 1.0000\n",
      "Epoch 874/1000\n",
      "8788/8788 - 0s - loss: 1.1527e-06 - accuracy: 1.0000\n",
      "Epoch 875/1000\n",
      "8788/8788 - 0s - loss: 1.1241e-06 - accuracy: 1.0000\n",
      "Epoch 876/1000\n",
      "8788/8788 - 0s - loss: 1.0846e-06 - accuracy: 1.0000\n",
      "Epoch 877/1000\n",
      "8788/8788 - 0s - loss: 1.0279e-06 - accuracy: 1.0000\n",
      "Epoch 878/1000\n",
      "8788/8788 - 0s - loss: 9.9426e-07 - accuracy: 1.0000\n",
      "Epoch 879/1000\n",
      "8788/8788 - 1s - loss: 9.6079e-07 - accuracy: 1.0000\n",
      "Epoch 880/1000\n",
      "8788/8788 - 1s - loss: 9.3052e-07 - accuracy: 1.0000\n",
      "Epoch 881/1000\n",
      "8788/8788 - 1s - loss: 8.9967e-07 - accuracy: 1.0000\n",
      "Epoch 882/1000\n",
      "8788/8788 - 1s - loss: 8.6489e-07 - accuracy: 1.0000\n",
      "Epoch 883/1000\n",
      "8788/8788 - 1s - loss: 8.3210e-07 - accuracy: 1.0000\n",
      "Epoch 884/1000\n",
      "8788/8788 - 1s - loss: 8.0244e-07 - accuracy: 1.0000\n",
      "Epoch 885/1000\n",
      "8788/8788 - 1s - loss: 7.7376e-07 - accuracy: 1.0000\n",
      "Epoch 886/1000\n",
      "8788/8788 - 1s - loss: 7.4739e-07 - accuracy: 1.0000\n",
      "Epoch 887/1000\n",
      "8788/8788 - 0s - loss: 7.1639e-07 - accuracy: 1.0000\n",
      "Epoch 888/1000\n",
      "8788/8788 - 0s - loss: 6.8324e-07 - accuracy: 1.0000\n",
      "Epoch 889/1000\n",
      "8788/8788 - 0s - loss: 6.5072e-07 - accuracy: 1.0000\n",
      "Epoch 890/1000\n",
      "8788/8788 - 0s - loss: 6.3106e-07 - accuracy: 1.0000\n",
      "Epoch 891/1000\n",
      "8788/8788 - 0s - loss: 6.0726e-07 - accuracy: 1.0000\n",
      "Epoch 892/1000\n",
      "8788/8788 - 0s - loss: 5.9082e-07 - accuracy: 1.0000\n",
      "Epoch 893/1000\n",
      "8788/8788 - 0s - loss: 5.7422e-07 - accuracy: 1.0000\n",
      "Epoch 894/1000\n",
      "8788/8788 - 1s - loss: 5.6427e-07 - accuracy: 1.0000\n",
      "Epoch 895/1000\n",
      "8788/8788 - 1s - loss: 6.3865e-07 - accuracy: 1.0000\n",
      "Epoch 896/1000\n",
      "8788/8788 - 1s - loss: 5.1902e-07 - accuracy: 1.0000\n",
      "Epoch 897/1000\n",
      "8788/8788 - 1s - loss: 5.2092e-07 - accuracy: 1.0000\n",
      "Epoch 898/1000\n",
      "8788/8788 - 1s - loss: 5.0041e-07 - accuracy: 1.0000\n",
      "Epoch 899/1000\n",
      "8788/8788 - 1s - loss: 7.1781e-07 - accuracy: 1.0000\n",
      "Epoch 900/1000\n",
      "8788/8788 - 1s - loss: 5.6233e-07 - accuracy: 1.0000\n",
      "Epoch 901/1000\n",
      "8788/8788 - 1s - loss: 0.0028 - accuracy: 0.9994\n",
      "Epoch 902/1000\n",
      "8788/8788 - 1s - loss: 0.0030 - accuracy: 0.9995\n",
      "Epoch 903/1000\n",
      "8788/8788 - 0s - loss: 2.8447e-06 - accuracy: 1.0000\n",
      "Epoch 904/1000\n",
      "8788/8788 - 0s - loss: 2.3267e-06 - accuracy: 1.0000\n",
      "Epoch 905/1000\n",
      "8788/8788 - 0s - loss: 2.0674e-06 - accuracy: 1.0000\n",
      "Epoch 906/1000\n",
      "8788/8788 - 1s - loss: 1.8767e-06 - accuracy: 1.0000\n",
      "Epoch 907/1000\n",
      "8788/8788 - 1s - loss: 1.6996e-06 - accuracy: 1.0000\n",
      "Epoch 908/1000\n",
      "8788/8788 - 0s - loss: 1.5919e-06 - accuracy: 1.0000\n",
      "Epoch 909/1000\n",
      "8788/8788 - 0s - loss: 1.4798e-06 - accuracy: 1.0000\n",
      "Epoch 910/1000\n",
      "8788/8788 - 0s - loss: 1.4138e-06 - accuracy: 1.0000\n",
      "Epoch 911/1000\n",
      "8788/8788 - 0s - loss: 1.3371e-06 - accuracy: 1.0000\n",
      "Epoch 912/1000\n",
      "8788/8788 - 0s - loss: 1.2729e-06 - accuracy: 1.0000\n",
      "Epoch 913/1000\n",
      "8788/8788 - 1s - loss: 1.2055e-06 - accuracy: 1.0000\n",
      "Epoch 914/1000\n",
      "8788/8788 - 0s - loss: 1.1710e-06 - accuracy: 1.0000\n",
      "Epoch 915/1000\n",
      "8788/8788 - 1s - loss: 1.1102e-06 - accuracy: 1.0000\n",
      "Epoch 916/1000\n",
      "8788/8788 - 1s - loss: 1.0584e-06 - accuracy: 1.0000\n",
      "Epoch 917/1000\n",
      "8788/8788 - 1s - loss: 1.0041e-06 - accuracy: 1.0000\n",
      "Epoch 918/1000\n",
      "8788/8788 - 1s - loss: 9.8475e-07 - accuracy: 1.0000\n",
      "Epoch 919/1000\n",
      "8788/8788 - 0s - loss: 9.4335e-07 - accuracy: 1.0000\n",
      "Epoch 920/1000\n",
      "8788/8788 - 0s - loss: 8.8381e-07 - accuracy: 1.0000\n",
      "Epoch 921/1000\n",
      "8788/8788 - 1s - loss: 8.4683e-07 - accuracy: 1.0000\n",
      "Epoch 922/1000\n",
      "8788/8788 - 1s - loss: 8.1519e-07 - accuracy: 1.0000\n",
      "Epoch 923/1000\n",
      "8788/8788 - 1s - loss: 7.8510e-07 - accuracy: 1.0000\n",
      "Epoch 924/1000\n",
      "8788/8788 - 1s - loss: 7.6451e-07 - accuracy: 1.0000\n",
      "Epoch 925/1000\n",
      "8788/8788 - 1s - loss: 7.4111e-07 - accuracy: 1.0000\n",
      "Epoch 926/1000\n",
      "8788/8788 - 1s - loss: 7.1981e-07 - accuracy: 1.0000\n",
      "Epoch 927/1000\n",
      "8788/8788 - 1s - loss: 7.0180e-07 - accuracy: 1.0000\n",
      "Epoch 928/1000\n",
      "8788/8788 - 1s - loss: 6.7310e-07 - accuracy: 1.0000\n",
      "Epoch 929/1000\n",
      "8788/8788 - 0s - loss: 6.6007e-07 - accuracy: 1.0000\n",
      "Epoch 930/1000\n",
      "8788/8788 - 0s - loss: 6.4250e-07 - accuracy: 1.0000\n",
      "Epoch 931/1000\n",
      "8788/8788 - 0s - loss: 6.1254e-07 - accuracy: 1.0000\n",
      "Epoch 932/1000\n",
      "8788/8788 - 0s - loss: 6.0823e-07 - accuracy: 1.0000\n",
      "Epoch 933/1000\n",
      "8788/8788 - 1s - loss: 5.6993e-07 - accuracy: 1.0000\n",
      "Epoch 934/1000\n",
      "8788/8788 - 1s - loss: 5.6485e-07 - accuracy: 1.0000\n",
      "Epoch 935/1000\n",
      "8788/8788 - 1s - loss: 4.9413e-07 - accuracy: 1.0000\n",
      "Epoch 936/1000\n",
      "8788/8788 - 1s - loss: 4.8197e-07 - accuracy: 1.0000\n",
      "Epoch 937/1000\n",
      "8788/8788 - 1s - loss: 4.7019e-07 - accuracy: 1.0000\n",
      "Epoch 938/1000\n",
      "8788/8788 - 0s - loss: 4.5976e-07 - accuracy: 1.0000\n",
      "Epoch 939/1000\n",
      "8788/8788 - 0s - loss: 4.4890e-07 - accuracy: 1.0000\n",
      "Epoch 940/1000\n",
      "8788/8788 - 1s - loss: 4.2798e-07 - accuracy: 1.0000\n",
      "Epoch 941/1000\n",
      "8788/8788 - 1s - loss: 4.1878e-07 - accuracy: 1.0000\n",
      "Epoch 942/1000\n",
      "8788/8788 - 0s - loss: 4.0084e-07 - accuracy: 1.0000\n",
      "Epoch 943/1000\n",
      "8788/8788 - 1s - loss: 3.8858e-07 - accuracy: 1.0000\n",
      "Epoch 944/1000\n",
      "8788/8788 - 1s - loss: 3.6963e-07 - accuracy: 1.0000\n",
      "Epoch 945/1000\n",
      "8788/8788 - 0s - loss: 3.6239e-07 - accuracy: 1.0000\n",
      "Epoch 946/1000\n",
      "8788/8788 - 1s - loss: 3.7446e-07 - accuracy: 1.0000\n",
      "Epoch 947/1000\n",
      "8788/8788 - 0s - loss: 3.5451e-07 - accuracy: 1.0000\n",
      "Epoch 948/1000\n",
      "8788/8788 - 1s - loss: 3.2560e-07 - accuracy: 1.0000\n",
      "Epoch 949/1000\n",
      "8788/8788 - 1s - loss: 3.2708e-07 - accuracy: 1.0000\n",
      "Epoch 950/1000\n",
      "8788/8788 - 1s - loss: 3.1019e-07 - accuracy: 1.0000\n",
      "Epoch 951/1000\n",
      "8788/8788 - 0s - loss: 2.9242e-07 - accuracy: 1.0000\n",
      "Epoch 952/1000\n",
      "8788/8788 - 1s - loss: 2.7219e-06 - accuracy: 1.0000\n",
      "Epoch 953/1000\n",
      "8788/8788 - 1s - loss: 0.0037 - accuracy: 0.9994\n",
      "Epoch 954/1000\n",
      "8788/8788 - 1s - loss: 0.0073 - accuracy: 0.9991\n",
      "Epoch 955/1000\n",
      "8788/8788 - 1s - loss: 1.4299e-06 - accuracy: 1.0000\n",
      "Epoch 956/1000\n",
      "8788/8788 - 1s - loss: 1.2091e-06 - accuracy: 1.0000\n",
      "Epoch 957/1000\n",
      "8788/8788 - 1s - loss: 1.0477e-06 - accuracy: 1.0000\n",
      "Epoch 958/1000\n",
      "8788/8788 - 1s - loss: 9.3635e-07 - accuracy: 1.0000\n",
      "Epoch 959/1000\n",
      "8788/8788 - 1s - loss: 8.2458e-07 - accuracy: 1.0000\n",
      "Epoch 960/1000\n",
      "8788/8788 - 1s - loss: 7.4768e-07 - accuracy: 1.0000\n",
      "Epoch 961/1000\n",
      "8788/8788 - 1s - loss: 6.8494e-07 - accuracy: 1.0000\n",
      "Epoch 962/1000\n",
      "8788/8788 - 1s - loss: 6.3602e-07 - accuracy: 1.0000\n",
      "Epoch 963/1000\n",
      "8788/8788 - 1s - loss: 5.9488e-07 - accuracy: 1.0000\n",
      "Epoch 964/1000\n",
      "8788/8788 - 1s - loss: 5.5811e-07 - accuracy: 1.0000\n",
      "Epoch 965/1000\n",
      "8788/8788 - 1s - loss: 5.2803e-07 - accuracy: 1.0000\n",
      "Epoch 966/1000\n",
      "8788/8788 - 1s - loss: 5.0653e-07 - accuracy: 1.0000\n",
      "Epoch 967/1000\n",
      "8788/8788 - 0s - loss: 4.8868e-07 - accuracy: 1.0000\n",
      "Epoch 968/1000\n",
      "8788/8788 - 0s - loss: 4.7362e-07 - accuracy: 1.0000\n",
      "Epoch 969/1000\n",
      "8788/8788 - 0s - loss: 4.6034e-07 - accuracy: 1.0000\n",
      "Epoch 970/1000\n",
      "8788/8788 - 0s - loss: 4.4921e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 971/1000\n",
      "8788/8788 - 0s - loss: 4.3771e-07 - accuracy: 1.0000\n",
      "Epoch 972/1000\n",
      "8788/8788 - 0s - loss: 4.2847e-07 - accuracy: 1.0000\n",
      "Epoch 973/1000\n",
      "8788/8788 - 0s - loss: 4.2002e-07 - accuracy: 1.0000\n",
      "Epoch 974/1000\n",
      "8788/8788 - 1s - loss: 4.1182e-07 - accuracy: 1.0000\n",
      "Epoch 975/1000\n",
      "8788/8788 - 0s - loss: 4.0875e-07 - accuracy: 1.0000\n",
      "Epoch 976/1000\n",
      "8788/8788 - 0s - loss: 4.0462e-07 - accuracy: 1.0000\n",
      "Epoch 977/1000\n",
      "8788/8788 - 1s - loss: 4.0261e-07 - accuracy: 1.0000\n",
      "Epoch 978/1000\n",
      "8788/8788 - 1s - loss: 3.9709e-07 - accuracy: 1.0000\n",
      "Epoch 979/1000\n",
      "8788/8788 - 0s - loss: 3.9034e-07 - accuracy: 1.0000\n",
      "Epoch 980/1000\n",
      "8788/8788 - 0s - loss: 3.8584e-07 - accuracy: 1.0000\n",
      "Epoch 981/1000\n",
      "8788/8788 - 0s - loss: 3.7952e-07 - accuracy: 1.0000\n",
      "Epoch 982/1000\n",
      "8788/8788 - 0s - loss: 3.8111e-07 - accuracy: 1.0000\n",
      "Epoch 983/1000\n",
      "8788/8788 - 0s - loss: 3.6970e-07 - accuracy: 1.0000\n",
      "Epoch 984/1000\n",
      "8788/8788 - 1s - loss: 3.6667e-07 - accuracy: 1.0000\n",
      "Epoch 985/1000\n",
      "8788/8788 - 0s - loss: 3.5914e-07 - accuracy: 1.0000\n",
      "Epoch 986/1000\n",
      "8788/8788 - 1s - loss: 3.5302e-07 - accuracy: 1.0000\n",
      "Epoch 987/1000\n",
      "8788/8788 - 1s - loss: 3.4599e-07 - accuracy: 1.0000\n",
      "Epoch 988/1000\n",
      "8788/8788 - 1s - loss: 3.4153e-07 - accuracy: 1.0000\n",
      "Epoch 989/1000\n",
      "8788/8788 - 0s - loss: 3.3002e-07 - accuracy: 1.0000\n",
      "Epoch 990/1000\n",
      "8788/8788 - 0s - loss: 3.2402e-07 - accuracy: 1.0000\n",
      "Epoch 991/1000\n",
      "8788/8788 - 0s - loss: 3.2230e-07 - accuracy: 1.0000\n",
      "Epoch 992/1000\n",
      "8788/8788 - 1s - loss: 3.2073e-07 - accuracy: 1.0000\n",
      "Epoch 993/1000\n",
      "8788/8788 - 0s - loss: 3.0990e-07 - accuracy: 1.0000\n",
      "Epoch 994/1000\n",
      "8788/8788 - 0s - loss: 3.1793e-07 - accuracy: 1.0000\n",
      "Epoch 995/1000\n",
      "8788/8788 - 0s - loss: 2.9404e-07 - accuracy: 1.0000\n",
      "Epoch 996/1000\n",
      "8788/8788 - 0s - loss: 2.8124e-07 - accuracy: 1.0000\n",
      "Epoch 997/1000\n",
      "8788/8788 - 0s - loss: 2.8738e-07 - accuracy: 1.0000\n",
      "Epoch 998/1000\n",
      "8788/8788 - 0s - loss: 2.8405e-07 - accuracy: 1.0000\n",
      "Epoch 999/1000\n",
      "8788/8788 - 0s - loss: 2.6922e-07 - accuracy: 1.0000\n",
      "Epoch 1000/1000\n",
      "8788/8788 - 0s - loss: 3.0799e-07 - accuracy: 1.0000\n",
      "2930/2930 - 0s - loss: 0.0686 - accuracy: 0.9966\n",
      "Deep Neural Network - Loss: 0.06862677155876719, Accuracy: 0.9965870380401611\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=8, activation='relu', input_dim=26))\n",
    "deep_model.add(Dense(units=8, activation='relu'))\n",
    "deep_model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "deep_model.summary()\n",
    "\n",
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "deep_model.fit(\n",
    "    X_train_scaled_rf,\n",
    "    y_train_categorical,\n",
    "    epochs=1000,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n",
    "model_loss, model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled_rf,y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ynew = deep_model.predict_classes(Xx_test_scaled_rf)\n",
    "for i in range(len(Xx_test_scaled_rf)):\n",
    "    if (ynew[i] == 1):\n",
    "        print(i,\"X=%s, Predicted=%s\" % (Xx_test_scaled_rf[i], ynew[i]),mvp_2020.iloc[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
